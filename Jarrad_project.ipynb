{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 23:06:34.448938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 23:06:34.687740: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-11 23:06:35.860345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-11 23:06:35.860449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-11 23:06:35.860455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 23:06:37.501819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:37.511135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:37.511174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "print(tf.version)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0             1  0.4375    0.0      1.png\n",
      "1             2  0.8125    1.0      2.png\n",
      "2             3  0.4375    1.0      3.png\n",
      "3             4  0.6250    1.0      4.png\n",
      "4             5  0.5000    0.0      5.png\n",
      "...         ...     ...    ...        ...\n",
      "13788     13794  0.6250    1.0  13794.png\n",
      "13789     13795  0.4375    1.0  13795.png\n",
      "13790     13796  0.5625    0.0  13796.png\n",
      "13791     13797  0.6250    0.0  13797.png\n",
      "13792     13798  0.6875    1.0  13798.png\n",
      "\n",
      "[13793 rows x 4 columns]\n",
      "Found 13798 files belonging to 1 classes.\n",
      "Using 11039 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 23:06:38.227992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 23:06:38.229618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:38.229702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:38.229737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:40.086768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:40.086855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:40.086862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-11 23:06:40.086889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:06:40.087369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_size = [240, 320]\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "#df['label'] = [df[\"angle\"], df[\"speed\"]]\n",
    "print(df)\n",
    "\n",
    "\n",
    "# x_train = df[0:int(len(df) * 0.6)]\n",
    "#x_validate = df[int(len(df) * 0.6):int(len(df) * 0.8)]\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.8)]\n",
    "x_validate = df[int(len(df) * 0.8):]\n",
    "\n",
    "training_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"machine-learning-in-science-ii-2023/training_data\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11034 validated image filenames.\n",
      "Found 2759 validated image filenames.\n",
      "Found 2759 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    batch_size=16,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    class_mode='other')\n",
    "\n",
    "evaluate_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    class_mode='other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "\n",
    "# CNN base\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten()),\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.7))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2,  activation='relu', kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEzHX-7ESeCl",
    "outputId": "b1ad1ed9-87ef-4a37-b392-59e9ebb807d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 238, 318, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 238, 318, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 119, 159, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 117, 157, 16)      4624      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 117, 157, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 58, 78, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 76, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 54, 74, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 54, 74, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 27, 37, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 25, 35, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 25, 35, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 15, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 10, 15, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4480)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1147136   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,279,986\n",
      "Trainable params: 1,278,738\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 23:06:43.261300: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-03-11 23:06:45.210089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-11 23:06:49.113900: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-11 23:06:53.271922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-11 23:06:53.298611: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2dc7f1f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-11 23:06:53.298696: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-11 23:06:53.317055: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-11 23:06:53.591736: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-11 23:06:53.714519: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 62s 66ms/step - loss: 0.1255 - val_loss: 0.0430\n",
      "Epoch 2/5\n",
      "690/690 [==============================] - 45s 65ms/step - loss: 0.0467 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "690/690 [==============================] - 47s 68ms/step - loss: 0.0390 - val_loss: 0.0263\n",
      "Epoch 4/5\n",
      "690/690 [==============================] - 41s 59ms/step - loss: 0.0336 - val_loss: 0.0336\n",
      "Epoch 5/5\n",
      "690/690 [==============================] - 39s 57ms/step - loss: 0.0335 - val_loss: 0.0254\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1020 files belonging to 1 classes.\n",
      "WARNING:tensorflow:From /home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "32/32 [==============================] - 4s 104ms/step\n",
      "(1020, 2)\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('model.h6')\n",
    "\n",
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"machine-learning-in-science-ii-2023/test_data\",\n",
    "    image_size=img_size,\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "test_images = test_images.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "prediction = model.predict(test_images)\n",
    "print(prediction.shape)\n",
    "import math\n",
    "\n",
    "a= prediction[:,0]\n",
    "b= prediction[:,1]\n",
    "# b+=0.5\n",
    "# b= np.floor(b)\n",
    "\n",
    "submissiondata={\"angle\":a , \"speed\":b} \n",
    "df = pd.DataFrame(submissiondata)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 70ms/step - loss: 0.0254\n",
      "Found 2759 validated image filenames.\n",
      "87/87 [==============================] - 6s 68ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_loss = model.evaluate(\n",
    "    eval_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    class_mode=None)\n",
    "\n",
    "\n",
    "\n",
    "#test_loss\n",
    "\n",
    "predict_model = model.predict(test_generator, verbose =1)\n",
    "\n",
    "# y = np.concatenate([y for x, y in x_evaluate], axis=0)\n",
    "# true = np.argmax(y, axis = 1)\n",
    "\n",
    "# print(true)\n",
    "# predict_model = np.argmax(predict_model, axis = 1)\n",
    "# print(predict_model)\n",
    "\n",
    "# print(classification_report(true, predict_model, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis2_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83badb9abfa833c8f944a253dee1819f5989bd8424f7fb8e0e95b6cecc08b674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
