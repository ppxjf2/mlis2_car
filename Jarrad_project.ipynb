{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "  \n",
    "print(tf.version)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os\n",
    "\n",
    "from keras.applications import VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, Xception, MobileNet, DenseNet121, \\\n",
    "    NASNetMobile, EfficientNetB0, MobileNetV2, MobileNetV3Large\n",
    "from tensorflow.python.keras.layers import Conv2D, Flatten, Dropout, Dense, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0           414  0.8125    1.0    414.png\n",
      "1         17532  0.6875    1.0  17532.png\n",
      "2         16480  0.3125    0.0  16480.png\n",
      "3          6450  0.6875    0.0   6450.png\n",
      "4         12314  0.6250    0.0  12314.png\n",
      "...         ...     ...    ...        ...\n",
      "14821      9844  0.6875    1.0   9844.png\n",
      "14822     12367  0.5000    1.0  12367.png\n",
      "14823       343  0.9375    1.0    343.png\n",
      "14824      3838  0.6875    0.0   3838.png\n",
      "14825     13301  0.5000    1.0  13301.png\n",
      "\n",
      "[14826 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_size = [240, 320]\n",
    "\n",
    "# df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "# df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# print(df)\n",
    "\n",
    "#df.to_csv(\"training_norm_shuffle.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm_shuffle.csv')\n",
    "print(df)\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.6)]\n",
    "x_validate = df[int(len(df) * 0.6):int(len(df) * 0.8)]\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "# x_train = df[0:int(len(df) * 0.8)]\n",
    "# x_validate = df[int(len(df) * 0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8895 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2966 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shift = 0.1\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=shift,\n",
    "    height_shift_range=shift\n",
    ")\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "#print(train_generator)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "evaluate_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:49:29.128611: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 17:49:29.132122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-26 17:49:29.132187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-26 17:49:29.132210: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-26 17:49:30.413334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-26 17:49:30.413722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-26 17:49:30.413733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-26 17:49:30.413793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-26 17:49:30.413892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "input_shape = [240, 320, 3]\n",
    "transfer = MobileNetV2(\n",
    "    input_shape=input_shape, \n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    classifier_activation=\"relu\"\n",
    ")\n",
    "\n",
    "for layer in transfer.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# CNN base\n",
    "model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=shape))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(transfer)\n",
    "model.build()\n",
    "        \n",
    "model.add(layers.Conv2D(128, (3, 3), strides= (2,2), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "model.add(layers.Flatten()),\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# model.add(layers.Dense(16, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2,  activation='relu', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEzHX-7ESeCl",
    "outputId": "b1ad1ed9-87ef-4a37-b392-59e9ebb807d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 3, 4, 128)         1474688   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3, 4, 128)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                98368     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,831,938\n",
      "Trainable params: 1,576,130\n",
      "Non-trainable params: 2,255,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:49:36.021329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-26 17:49:41.923241: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-26 17:49:46.652172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-26 17:49:46.685163: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2cb44360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-26 17:49:46.685264: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-26 17:49:46.715033: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-26 17:49:47.087889: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-26 17:49:47.129324: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 120s 187ms/step - loss: 0.0915 - val_loss: 0.0264\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.0304 - val_loss: 0.0198\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 100s 181ms/step - loss: 0.0233 - val_loss: 0.0154\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0211 - val_loss: 0.0144\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0188 - val_loss: 0.0135\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 100s 179ms/step - loss: 0.0178 - val_loss: 0.0133\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 101s 182ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 100s 180ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 99s 179ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 98s 177ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 100s 180ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 100s 179ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 109s 195ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 103s 184ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 107s 192ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 107s 193ms/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 109s 196ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 103s 184ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 100s 180ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 101s 182ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 100s 181ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 30/100\n",
      "556/556 [==============================] - 99s 179ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 31/100\n",
      "556/556 [==============================] - 100s 180ms/step - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 33/100\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 34/100\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "556/556 [==============================] - 100s 179ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "556/556 [==============================] - 99s 177ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "556/556 [==============================] - 100s 180ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 39/100\n",
      "556/556 [==============================] - 101s 182ms/step - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "556/556 [==============================] - 102s 184ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 41/100\n",
      "556/556 [==============================] - 102s 183ms/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "556/556 [==============================] - 100s 180ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 43/100\n",
      "556/556 [==============================] - ETA: 0s - loss: 0.0079Restoring model weights from the end of the best epoch: 23.\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 43: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  file type\n",
      "0        1.png     1  png\n",
      "1        2.png     2  png\n",
      "2        3.png     3  png\n",
      "3        4.png     4  png\n",
      "4        5.png     5  png\n",
      "...        ...   ...  ...\n",
      "1015  1016.png  1016  png\n",
      "1016  1017.png  1017  png\n",
      "1017  1018.png  1018  png\n",
      "1018  1019.png  1019  png\n",
      "1019  1020.png  1020  png\n",
      "\n",
      "[1020 rows x 3 columns]\n",
      "Found 1020 validated image filenames.\n",
      "<keras.preprocessing.image.DataFrameIterator object at 0x7f796c1a2640>\n",
      "32/32 [==============================] - 4s 106ms/step\n",
      "(1020, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = os.listdir(\"machine-learning-in-science-ii-2023/test_data/test_data\") \n",
    "\n",
    "df = pd.DataFrame(filename)\n",
    "df.columns = [\"filename\"]\n",
    "\n",
    "df[['file', 'type']] = df.filename.str.split(\".\", expand = True)\n",
    "df[\"file\"] = df[\"file\"].astype(str).astype(int)\n",
    "\n",
    "df.sort_values(by=['file'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_images = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=\"machine-learning-in-science-ii-2023/test_data/test_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)\n",
    "\n",
    "print(test_images)\n",
    "\n",
    "prediction = model.predict(test_images)\n",
    "print(prediction.shape)\n",
    "import math\n",
    "\n",
    "a= prediction[:,0]\n",
    "b= prediction[:,1]\n",
    "b+=0.5\n",
    "b= np.floor(b)\n",
    "\n",
    "submissiondata={\"angle\":a , \"speed\":b} \n",
    "df = pd.DataFrame(submissiondata)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 88ms/step - loss: 0.0108\n",
      "Found 2966 validated image filenames.\n",
      "93/93 [==============================] - 7s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_loss = model.evaluate(\n",
    "    eval_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)\n",
    "\n",
    "\n",
    "prediction = model.predict(test_generator, verbose =1)\n",
    "\n",
    "a= prediction[:,0]\n",
    "b= prediction[:,1]\n",
    "b+=0.5\n",
    "b= np.floor(b)\n",
    "\n",
    "submissiondata={\"angle\":a , \"speed\":b} \n",
    "df = pd.DataFrame(submissiondata)\n",
    "df.index += 1 \n",
    "df.to_csv('evaluate.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = abs(x_evaluate[\"angle\"] - a)\n",
    "\n",
    "results = pd.DataFrame({\"Train\":x_evaluate[\"angle\"], \"Predicted\":a, \"Difference\":diff})\n",
    "#results\n",
    "\n",
    "#results.to_csv('evaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Train\":x_evaluate[\"speed\"],\"Predicted\":b})\n",
    "#results\n",
    "\n",
    "#results.to_csv('evaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = model.to_json()\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 3, 4, 128)         1474688   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3, 4, 128)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                98368     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,831,938\n",
      "Trainable params: 98,882\n",
      "Non-trainable params: 3,733,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# model2 = model_from_json(model_architecture)\n",
    "# model2.load_weights(\"model_weights.h5\")\n",
    "\n",
    "from keras.models import load_model\n",
    "model2 = load_model('model.h5')\n",
    "\n",
    "\n",
    "#model2.trainable = True\n",
    "\n",
    "for layer in model2.layers[:2]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "556/556 [==============================] - 111s 193ms/step - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 2/300\n",
      "556/556 [==============================] - 102s 183ms/step - loss: 0.0124 - val_loss: 0.0075\n",
      "Epoch 3/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 4/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 5/300\n",
      "556/556 [==============================] - 98s 177ms/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 6/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 7/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0122 - val_loss: 0.0076\n",
      "Epoch 8/300\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 9/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 10/300\n",
      "556/556 [==============================] - 99s 179ms/step - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 11/300\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.0122 - val_loss: 0.0076\n",
      "Epoch 12/300\n",
      "556/556 [==============================] - 99s 177ms/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 13/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 14/300\n",
      "556/556 [==============================] - 99s 177ms/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 15/300\n",
      "556/556 [==============================] - 98s 175ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 16/300\n",
      "556/556 [==============================] - 97s 175ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 17/300\n",
      "556/556 [==============================] - 100s 181ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 18/300\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 19/300\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.0116 - val_loss: 0.0075\n",
      "Epoch 20/300\n",
      "556/556 [==============================] - 98s 177ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 21/300\n",
      "556/556 [==============================] - 97s 175ms/step - loss: 0.0114 - val_loss: 0.0076\n",
      "Epoch 22/300\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 23/300\n",
      "556/556 [==============================] - 97s 174ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 24/300\n",
      "556/556 [==============================] - 98s 175ms/step - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 25/300\n",
      "556/556 [==============================] - 97s 174ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 26/300\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 27/300\n",
      "556/556 [==============================] - 99s 177ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 28/300\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 29/300\n",
      "556/556 [==============================] - 1054s 2s/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 30/300\n",
      "556/556 [==============================] - 100s 178ms/step - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 31/300\n",
      "556/556 [==============================] - ETA: 0s - loss: 0.0116Restoring model weights from the end of the best epoch: 1.\n",
      "556/556 [==============================] - 186s 334ms/step - loss: 0.0116 - val_loss: 0.0075\n",
      "Epoch 31: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001), # 1e-5 \n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0005,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 79ms/step - loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_loss = model2.evaluate(\n",
    "    eval_generator,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save(\"model-fine-tuning.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 100ms/step\n",
      "(1020, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction = model2.predict(test_images)\n",
    "print(prediction.shape)\n",
    "import math\n",
    "\n",
    "a= prediction[:,0]\n",
    "b= prediction[:,1]\n",
    "b+=0.5\n",
    "b= np.floor(b)\n",
    "\n",
    "submissiondata={\"angle\":a , \"speed\":b} \n",
    "df = pd.DataFrame(submissiondata)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission-fine-tuning.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14826 validated image filenames.\n",
      "464/464 [==============================] - 41s 88ms/step\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import load_model\n",
    "# model3 = load_model('model-best.h5')\n",
    "\n",
    "# df_all = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "# df_all['filename'] = df_all[\"image_id\"].astype(str) + \".png\"\n",
    "\n",
    "# clean_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# clean_generator = clean_datagen.flow_from_dataframe(\n",
    "#     dataframe=df_all,\n",
    "#     directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "#     x_col=\"filename\",\n",
    "#     target_size=img_size,\n",
    "#     shuffle=False,\n",
    "#     class_mode=None)\n",
    "\n",
    "\n",
    "# prediction = model.predict(clean_generator, verbose =1)\n",
    "\n",
    "# a= prediction[:,0]\n",
    "# b= prediction[:,1]\n",
    "# b+=0.5\n",
    "# b= np.floor(b)\n",
    "\n",
    "\n",
    "# diff = abs(df_all[\"angle\"] - a)\n",
    "# results = pd.DataFrame({\"image_id\":df_all[\"image_id\"], \"Actual Angle\":df_all[\"angle\"], \"Predicted Angle\":a, \"Angle Difference\":diff, \"Actual Speed\":df_all[\"speed\"], \"Predicted Speed\":b})\n",
    "\n",
    "# df = pd.DataFrame(results)\n",
    "# df.to_csv('clean_results.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis2_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83badb9abfa833c8f944a253dee1819f5989bd8424f7fb8e0e95b6cecc08b674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
