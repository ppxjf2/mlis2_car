{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:27:16.184004: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 19:27:16.948231: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-29 19:27:19.162114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-29 19:27:19.162227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-29 19:27:19.162234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-29 19:27:21.641472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-29 19:27:21.754526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-29 19:27:21.754597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "import math\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os\n",
    "\n",
    "from keras.applications import VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, Xception, MobileNet, DenseNet121, NASNetMobile, EfficientNetB0, MobileNetV2, MobileNetV3Large\n",
    "from tensorflow.python.keras.layers import Conv2D, Flatten, Dropout, Dense, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import model_from_json\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0           414  0.8125    1.0    414.png\n",
      "1         17532  0.6875    1.0  17532.png\n",
      "2         16480  0.3125    0.0  16480.png\n",
      "3          6450  0.6875    0.0   6450.png\n",
      "4         12314  0.6250    0.0  12314.png\n",
      "...         ...     ...    ...        ...\n",
      "14821      9844  0.6875    1.0   9844.png\n",
      "14822     12367  0.5000    1.0  12367.png\n",
      "14823       343  0.9375    1.0    343.png\n",
      "14824      3838  0.6875    0.0   3838.png\n",
      "14825     13301  0.5000    1.0  13301.png\n",
      "\n",
      "[14826 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "# df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df.to_csv(\"training_norm_shuffle.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm_shuffle.csv')\n",
    "print(df)\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.6)]\n",
    "x_validate = df[int(len(df) * 0.6):int(len(df) * 0.8)]\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "# x_train = df[0:int(len(df) * 0.8)]\n",
    "# x_validate = df[int(len(df) * 0.8):]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8895 validated image filenames.\n",
      "Found 8895 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2966 validated image filenames.\n",
      "Found 2966 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 32\n",
    "img_size = [240, 320]\n",
    "shift = 0.1\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=shift,\n",
    "    height_shift_range=shift\n",
    ")\n",
    "\n",
    "speed_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "speed_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "evaluate_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "speed_eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  file type\n",
      "0        1.png     1  png\n",
      "1        2.png     2  png\n",
      "2        3.png     3  png\n",
      "3        4.png     4  png\n",
      "4        5.png     5  png\n",
      "...        ...   ...  ...\n",
      "1015  1016.png  1016  png\n",
      "1016  1017.png  1017  png\n",
      "1017  1018.png  1018  png\n",
      "1018  1019.png  1019  png\n",
      "1019  1020.png  1020  png\n",
      "\n",
      "[1020 rows x 3 columns]\n",
      "Found 1020 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "filename = os.listdir(\"machine-learning-in-science-ii-2023/test_data/test_data\") \n",
    "\n",
    "df = pd.DataFrame(filename)\n",
    "df.columns = [\"filename\"]\n",
    "\n",
    "df[['file', 'type']] = df.filename.str.split(\".\", expand = True)\n",
    "df[\"file\"] = df[\"file\"].astype(str).astype(int)\n",
    "\n",
    "df.sort_values(by=['file'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df)\n",
    "submission_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "submission_images = submission_datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=\"machine-learning-in-science-ii-2023/test_data/test_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "input_shape = [240, 320, 3]\n",
    "transfer = MobileNetV2(\n",
    "    input_shape=input_shape, \n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    classifier_activation=\"relu\"\n",
    ")\n",
    "\n",
    "for layer in transfer.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 4, 1280)        14746880  \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 3, 4, 1280)       5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 15360)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               1966208   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,985,281\n",
      "Trainable params: 16,726,913\n",
      "Non-trainable params: 2,258,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Speed CNN base\n",
    "speed_model = models.Sequential()\n",
    "\n",
    "speed_model.add(transfer)\n",
    "speed_model.build()\n",
    "        \n",
    "speed_model.add(layers.Conv2D(1280, (3, 3), strides=(2,2), activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "\n",
    "speed_model.add(layers.Flatten()),\n",
    "\n",
    "speed_model.add(layers.Dense(128, activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "speed_model.add(layers.Dropout(0.2))\n",
    "\n",
    "speed_model.add(layers.Dense(64, activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "speed_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "speed_model.add(layers.Flatten())\n",
    "speed_model.add(layers.Dense(1,  activation='sigmoid'))\n",
    "\n",
    "speed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 4, 128)         1474688   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 3, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               196736    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,930,561\n",
      "Trainable params: 1,674,625\n",
      "Non-trainable params: 2,255,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Angle CNN base\n",
    "angle_model = models.Sequential()\n",
    "\n",
    "angle_model.add(transfer)\n",
    "angle_model.build()\n",
    "        \n",
    "angle_model.add(layers.Conv2D(128, (3, 3), strides=(2,2), activation='relu'))\n",
    "angle_model.add(layers.BatchNormalization())\n",
    "\n",
    "angle_model.add(layers.Flatten()),\n",
    "\n",
    "# model_1.add(layers.Dense(128, activation='relu'))\n",
    "angle_model.add(layers.Dense(128, activation='relu'))\n",
    "angle_model.add(layers.BatchNormalization())\n",
    "angle_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "angle_model.add(layers.Flatten())\n",
    "angle_model.add(layers.Dense(1,  activation='relu'))\n",
    "\n",
    "angle_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_model.build()\n",
    "#angle_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "278/278 [==============================] - 112s 385ms/step - loss: 0.0525 - val_loss: 0.0221\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 105s 377ms/step - loss: 0.0231 - val_loss: 0.0204\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 97s 349ms/step - loss: 0.0193 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 98s 353ms/step - loss: 0.0164 - val_loss: 0.0159\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 98s 354ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 99s 357ms/step - loss: 0.0122 - val_loss: 0.0166\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 100s 361ms/step - loss: 0.0109 - val_loss: 0.0142\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 100s 361ms/step - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 100s 361ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 100s 360ms/step - loss: 0.0089 - val_loss: 0.0147\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 100s 358ms/step - loss: 0.0076 - val_loss: 0.0167\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 104s 374ms/step - loss: 0.0082 - val_loss: 0.0152\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 90s 322ms/step - loss: 0.0079 - val_loss: 0.0138\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 93s 334ms/step - loss: 0.0072 - val_loss: 0.0141\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 95s 341ms/step - loss: 0.0067 - val_loss: 0.0142\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 99s 356ms/step - loss: 0.0057 - val_loss: 0.0156\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 99s 357ms/step - loss: 0.0067 - val_loss: 0.0140\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 100s 358ms/step - loss: 0.0069 - val_loss: 0.0154\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 112s 403ms/step - loss: 0.0061 - val_loss: 0.0155\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 94s 339ms/step - loss: 0.0063 - val_loss: 0.0125\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 98s 352ms/step - loss: 0.0053 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 93s 333ms/step - loss: 0.0061 - val_loss: 0.0155\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 92s 330ms/step - loss: 0.0066 - val_loss: 0.0135\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 91s 327ms/step - loss: 0.0060 - val_loss: 0.0137\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 92s 332ms/step - loss: 0.0054 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 92s 330ms/step - loss: 0.0057 - val_loss: 0.0139\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 91s 329ms/step - loss: 0.0051 - val_loss: 0.0122\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 92s 331ms/step - loss: 0.0048 - val_loss: 0.0128\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 93s 335ms/step - loss: 0.0055 - val_loss: 0.0128\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 90s 324ms/step - loss: 0.0043 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 101s 365ms/step - loss: 0.0036 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 96s 344ms/step - loss: 0.0043 - val_loss: 0.0132\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 100s 360ms/step - loss: 0.0049 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 99s 356ms/step - loss: 0.0042 - val_loss: 0.0116\n",
      "Epoch 35/100\n",
      "278/278 [==============================] - 99s 356ms/step - loss: 0.0033 - val_loss: 0.0139\n",
      "Epoch 36/100\n",
      "278/278 [==============================] - 99s 354ms/step - loss: 0.0033 - val_loss: 0.0147\n",
      "Epoch 37/100\n",
      "278/278 [==============================] - 99s 356ms/step - loss: 0.0039 - val_loss: 0.0128\n",
      "Epoch 38/100\n",
      "278/278 [==============================] - 99s 356ms/step - loss: 0.0036 - val_loss: 0.0118\n",
      "Epoch 39/100\n",
      "278/278 [==============================] - 97s 348ms/step - loss: 0.0028 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "278/278 [==============================] - 91s 328ms/step - loss: 0.0032 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "278/278 [==============================] - 97s 347ms/step - loss: 0.0036 - val_loss: 0.0122\n",
      "Epoch 42/100\n",
      "278/278 [==============================] - 101s 364ms/step - loss: 0.0029 - val_loss: 0.0125\n",
      "Epoch 43/100\n",
      "278/278 [==============================] - 106s 382ms/step - loss: 0.0046 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "278/278 [==============================] - 109s 392ms/step - loss: 0.0035 - val_loss: 0.0127\n",
      "Epoch 45/100\n",
      "278/278 [==============================] - 109s 390ms/step - loss: 0.0029 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "278/278 [==============================] - 107s 384ms/step - loss: 0.0026 - val_loss: 0.0109\n",
      "Epoch 47/100\n",
      "278/278 [==============================] - 106s 380ms/step - loss: 0.0025 - val_loss: 0.0116\n",
      "Epoch 48/100\n",
      "278/278 [==============================] - 106s 380ms/step - loss: 0.0031 - val_loss: 0.0121\n",
      "Epoch 49/100\n",
      "278/278 [==============================] - 106s 380ms/step - loss: 0.0028 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0027Restoring model weights from the end of the best epoch: 30.\n",
      "278/278 [==============================] - 105s 378ms/step - loss: 0.0027 - val_loss: 0.0122\n",
      "Epoch 50: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = speed_model.fit(\n",
    "    speed_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=speed_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 9s 98ms/step - loss: 0.0157\n"
     ]
    }
   ],
   "source": [
    "test_loss = speed_model.evaluate(\n",
    "    speed_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "278/278 [==============================] - 114s 394ms/step - loss: 0.3833 - val_loss: 0.2791\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 107s 384ms/step - loss: 0.2030 - val_loss: 0.1198\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 106s 381ms/step - loss: 0.1127 - val_loss: 0.0751\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 104s 374ms/step - loss: 0.0677 - val_loss: 0.0261\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 94s 337ms/step - loss: 0.0374 - val_loss: 0.0211\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 98s 353ms/step - loss: 0.0209 - val_loss: 0.0109\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 107s 383ms/step - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 107s 383ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 108s 388ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 111s 400ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 110s 396ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 110s 397ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 108s 389ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 115s 414ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 110s 396ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 109s 391ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 108s 389ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 110s 395ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 112s 401ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 107s 386ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 108s 388ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 123s 442ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 110s 397ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 105s 377ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 94s 338ms/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 98s 353ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 109s 390ms/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 110s 395ms/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 111s 399ms/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0056Restoring model weights from the end of the best epoch: 10.\n",
      "278/278 [==============================] - 110s 395ms/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 30: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 9s 95ms/step - loss: 0.0064\n"
     ]
    }
   ],
   "source": [
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model.save(\"speed-model.h5\")\n",
    "angle_model.save(\"angle-model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 105ms/step\n",
      "32/32 [==============================] - 3s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "angle_prediction = angle_model.predict(submission_images)\n",
    "speed_prediction = speed_model.predict(submission_images)\n",
    "\n",
    "speed_prediction = speed_prediction.flatten()\n",
    "angle_prediction = angle_prediction.flatten()\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "submission = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "df = pd.DataFrame(submission)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv', index_label=\"image_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = abs(x_evaluate[\"angle\"] - angle_prediction)\n",
    "results = pd.DataFrame({\"Train\":x_evaluate[\"angle\"], \"Predicted\":angle_prediction, \"Difference\":diff})\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 1020 does not match index length 2966",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m\"\u001b[39;49m\u001b[39mTrain\u001b[39;49m\u001b[39m\"\u001b[39;49m:x_evaluate[\u001b[39m\"\u001b[39;49m\u001b[39mspeed\u001b[39;49m\u001b[39m\"\u001b[39;49m],\u001b[39m\"\u001b[39;49m\u001b[39mPredicted\u001b[39;49m\u001b[39m\"\u001b[39;49m:speed_prediction})\n",
      "File \u001b[0;32m~/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/pandas/core/internals/construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m lengths[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m    676\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    677\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray length \u001b[39m\u001b[39m{\u001b[39;00mlengths[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m does not match index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    678\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m         )\n\u001b[0;32m--> 680\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     index \u001b[39m=\u001b[39m default_index(lengths[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 1020 does not match index length 2966"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Train\":x_evaluate[\"speed\"],\"Predicted\":speed_prediction})\n",
    "#results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 4, 128)         1474688   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 3, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               196736    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,930,561\n",
      "Trainable params: 3,033,985\n",
      "Non-trainable params: 896,576\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 4, 1280)        14746880  \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 3, 4, 1280)       5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 15360)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               1966208   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,985,281\n",
      "Trainable params: 18,086,273\n",
      "Non-trainable params: 899,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speed_model = load_model(\"speed-model.h5\")\n",
    "angle_model = load_model(\"angle-model.h5\")\n",
    "\n",
    "\n",
    "angle_transfer = angle_model.layers[0]\n",
    "angle_transfer.trainable = True\n",
    "\n",
    "for layer in angle_transfer.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "        \n",
    "angle_model.summary()\n",
    "\n",
    "\n",
    "speed_transfer = speed_model.layers[0]\n",
    "speed_transfer.trainable = True\n",
    "\n",
    "for layer in speed_transfer.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "speed_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speed_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0005,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "278/278 [==============================] - 114s 386ms/step - loss: 0.0124 - val_loss: 0.0096\n",
      "Epoch 2/300\n",
      "278/278 [==============================] - 115s 415ms/step - loss: 0.0097 - val_loss: 0.0219\n",
      "Epoch 3/300\n",
      "278/278 [==============================] - 118s 424ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 4/300\n",
      "278/278 [==============================] - 119s 429ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 5/300\n",
      "278/278 [==============================] - 118s 426ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 6/300\n",
      "278/278 [==============================] - 120s 431ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 7/300\n",
      "278/278 [==============================] - 120s 433ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 8/300\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 9/300\n",
      "278/278 [==============================] - 120s 432ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 10/300\n",
      "278/278 [==============================] - 118s 426ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 11/300\n",
      "278/278 [==============================] - 115s 413ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 12/300\n",
      "278/278 [==============================] - 115s 414ms/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 13/300\n",
      "278/278 [==============================] - 99s 357ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 14/300\n",
      "278/278 [==============================] - 114s 410ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 15/300\n",
      "278/278 [==============================] - 113s 405ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 16/300\n",
      "278/278 [==============================] - 113s 408ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 17/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 18/300\n",
      "278/278 [==============================] - 115s 412ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 19/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 20/300\n",
      "278/278 [==============================] - 115s 412ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 21/300\n",
      "278/278 [==============================] - 103s 369ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 22/300\n",
      "278/278 [==============================] - 117s 420ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 23/300\n",
      "278/278 [==============================] - 115s 415ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 24/300\n",
      "278/278 [==============================] - 116s 419ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 25/300\n",
      "278/278 [==============================] - 114s 409ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 26/300\n",
      "278/278 [==============================] - 114s 410ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 27/300\n",
      "278/278 [==============================] - 113s 408ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 28/300\n",
      "278/278 [==============================] - 115s 414ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 29/300\n",
      "278/278 [==============================] - 114s 410ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 30/300\n",
      "278/278 [==============================] - 114s 409ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 31/300\n",
      "278/278 [==============================] - 114s 410ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 32/300\n",
      "278/278 [==============================] - 113s 405ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 33/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 34/300\n",
      "278/278 [==============================] - 112s 404ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 35/300\n",
      "278/278 [==============================] - 114s 409ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 36/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 37/300\n",
      "278/278 [==============================] - 115s 412ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 38/300\n",
      "278/278 [==============================] - 114s 411ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 39/300\n",
      "278/278 [==============================] - 113s 407ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 40/300\n",
      "278/278 [==============================] - 113s 407ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 41/300\n",
      "278/278 [==============================] - 115s 412ms/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 42/300\n",
      "278/278 [==============================] - 114s 409ms/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 43/300\n",
      "278/278 [==============================] - 115s 413ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 44/300\n",
      "278/278 [==============================] - 116s 419ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 45/300\n",
      "278/278 [==============================] - 114s 410ms/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 46/300\n",
      "278/278 [==============================] - 115s 415ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 47/300\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0048Restoring model weights from the end of the best epoch: 17.\n",
      "278/278 [==============================] - 111s 400ms/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 47: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 9s 95ms/step - loss: 0.0058\n"
     ]
    }
   ],
   "source": [
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "278/278 [==============================] - 118s 403ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 2/300\n",
      "278/278 [==============================] - 112s 401ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 3/300\n",
      "278/278 [==============================] - 111s 398ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 4/300\n",
      "278/278 [==============================] - 112s 404ms/step - loss: 0.0066 - val_loss: 0.0114\n",
      "Epoch 5/300\n",
      "278/278 [==============================] - 112s 404ms/step - loss: 0.0051 - val_loss: 0.0110\n",
      "Epoch 6/300\n",
      "278/278 [==============================] - 113s 405ms/step - loss: 0.0051 - val_loss: 0.0110\n",
      "Epoch 7/300\n",
      "278/278 [==============================] - 112s 403ms/step - loss: 0.0041 - val_loss: 0.0115\n",
      "Epoch 8/300\n",
      "278/278 [==============================] - 112s 404ms/step - loss: 0.0044 - val_loss: 0.0118\n",
      "Epoch 9/300\n",
      "278/278 [==============================] - 113s 405ms/step - loss: 0.0029 - val_loss: 0.0122\n",
      "Epoch 10/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0033 - val_loss: 0.0127\n",
      "Epoch 11/300\n",
      "278/278 [==============================] - 113s 407ms/step - loss: 0.0029 - val_loss: 0.0122\n",
      "Epoch 12/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0030 - val_loss: 0.0133\n",
      "Epoch 13/300\n",
      "278/278 [==============================] - 112s 403ms/step - loss: 0.0032 - val_loss: 0.0119\n",
      "Epoch 14/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 15/300\n",
      "278/278 [==============================] - 113s 406ms/step - loss: 0.0029 - val_loss: 0.0120\n",
      "Epoch 16/300\n",
      "278/278 [==============================] - 115s 413ms/step - loss: 0.0020 - val_loss: 0.0125\n",
      "Epoch 17/300\n",
      "278/278 [==============================] - 116s 415ms/step - loss: 0.0024 - val_loss: 0.0120\n",
      "Epoch 18/300\n",
      "278/278 [==============================] - 117s 420ms/step - loss: 0.0027 - val_loss: 0.0130\n",
      "Epoch 19/300\n",
      "278/278 [==============================] - 114s 411ms/step - loss: 0.0022 - val_loss: 0.0111\n",
      "Epoch 20/300\n",
      "278/278 [==============================] - 115s 412ms/step - loss: 0.0020 - val_loss: 0.0113\n",
      "Epoch 21/300\n",
      "278/278 [==============================] - 114s 410ms/step - loss: 0.0019 - val_loss: 0.0116\n",
      "Epoch 22/300\n",
      "278/278 [==============================] - 115s 415ms/step - loss: 0.0015 - val_loss: 0.0123\n",
      "Epoch 23/300\n",
      "278/278 [==============================] - 115s 414ms/step - loss: 0.0017 - val_loss: 0.0120\n",
      "Epoch 24/300\n",
      "278/278 [==============================] - 115s 413ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 25/300\n",
      "278/278 [==============================] - 116s 417ms/step - loss: 0.0017 - val_loss: 0.0114\n",
      "Epoch 26/300\n",
      "278/278 [==============================] - 116s 417ms/step - loss: 0.0023 - val_loss: 0.0121\n",
      "Epoch 27/300\n",
      "278/278 [==============================] - 118s 424ms/step - loss: 0.0015 - val_loss: 0.0119\n",
      "Epoch 28/300\n",
      "278/278 [==============================] - 115s 414ms/step - loss: 0.0011 - val_loss: 0.0113\n",
      "Epoch 29/300\n",
      "278/278 [==============================] - 116s 416ms/step - loss: 0.0017 - val_loss: 0.0121\n",
      "Epoch 30/300\n",
      "278/278 [==============================] - 114s 411ms/step - loss: 0.0016 - val_loss: 0.0123\n",
      "Epoch 31/300\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0015Restoring model weights from the end of the best epoch: 1.\n",
      "278/278 [==============================] - 115s 412ms/step - loss: 0.0015 - val_loss: 0.0120\n",
      "Epoch 31: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = speed_model.fit(\n",
    "    speed_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=speed_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 9s 97ms/step - loss: 0.0167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_loss = speed_model.evaluate(\n",
    "    speed_eval_generator,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model.save(\"speed-model-fine-tuning.h5\")\n",
    "angle_model.save(\"angle-model-fine-tuning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 106ms/step\n",
      "32/32 [==============================] - 3s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "angle_prediction = angle_model.predict(submission_images)\n",
    "speed_prediction = speed_model.predict(submission_images)\n",
    "\n",
    "speed_prediction = speed_prediction.flatten()\n",
    "angle_prediction = angle_prediction.flatten()\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "submission = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "df = pd.DataFrame(submission)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission-fine-tuning.csv', index_label=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model-fine-tuning.hdf5\")\n",
    "plot_model(model, show_layer_names=True, show_shapes=True,show_layer_activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Image File ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model = load_model(\"speed-model.h5\")\n",
    "angle_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "x_all = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "x_all['filename'] = x_all[\"image_id\"].astype(str) + \".png\"\n",
    "\n",
    "clean_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "clean_generator = clean_datagen.flow_from_dataframe(\n",
    "    dataframe=x_all,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)\n",
    "\n",
    "angle_prediction = angle_model.predict(clean_generator)\n",
    "speed_prediction = speed_model.predict(clean_generator)\n",
    "\n",
    "# predict = model.predict(clean_generator)\n",
    "\n",
    "# angle_prediction = predict[:,0]\n",
    "# speed_prediction = predict[:,1]\n",
    "\n",
    "diff = abs(x_all[\"angle\"] - angle_prediction)\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "correct = (x_all[\"speed\"] == speed_prediction)\n",
    "\n",
    "clean_data = {\n",
    "    \"image_id\":x_all[\"image_id\"], \n",
    "    \"Actual Angle\":x_all[\"angle\"], \n",
    "    \"Predicted Angle\":angle_prediction, \n",
    "    \"Angle Difference\":diff, \n",
    "    \"Actual Speed\":x_all[\"speed\"], \n",
    "    \"Predicted Speed\":speed_prediction,\n",
    "    \"Correct?\":correct\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(clean_data)\n",
    "df.index += 1 \n",
    "#df.to_csv('clean-results.csv', index_label=\"image_id\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run other models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 136ms/step\n",
      "32/32 [==============================] - 3s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "angle_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "speed_model = load_model(\"sakthi-speed2.hdf5\")\n",
    "# best_model = load_model(\"best-model.h5\")\n",
    "\n",
    "speed_prediction = speed_model.predict(submission_images)\n",
    "angle_prediction = angle_model.predict(submission_images)\n",
    "# best_prediction = best_model.predict(submission_images)\n",
    "\n",
    "# print(speed_prediction)\n",
    "\n",
    "# speed_prediction = speed_prediction[0]\n",
    "\n",
    "speed_prediction = speed_prediction.flatten()\n",
    "angle_prediction = angle_prediction.flatten()\n",
    "\n",
    "\n",
    "# best_angle = best_prediction[:,0]\n",
    "# best_speed = best_prediction[:,1]\n",
    "\n",
    "\n",
    "# best_speed += 0.5\n",
    "# best_speed = np.floor(best_speed)\n",
    "\n",
    "# diff = abs(best_angle - angle_prediction)\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "# match = (best_speed == speed_prediction)\n",
    "\n",
    "# validate = {\n",
    "#     \"Best Angle\":best_angle, \n",
    "#     \"Jarrad Angle\":angle_prediction, \n",
    "#     \"Angle Difference\":diff, \n",
    "#     \"Best Speed\":best_speed, \n",
    "#     \"Sakthi Speed\":speed_prediction,\n",
    "#     \"Match\":match\n",
    "# }\n",
    "validate = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(validate)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv', index_label=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 21s 168ms/step - loss: 0.0364 - accuracy: 0.9939 - mse: 0.0051 - auc_2: 0.9963\n"
     ]
    }
   ],
   "source": [
    "speed_model = load_model(\"sakthi-speed2.hdf5\")\n",
    "\n",
    "test_loss = speed_model.evaluate(\n",
    "    speed_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis2_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83badb9abfa833c8f944a253dee1819f5989bd8424f7fb8e0e95b6cecc08b674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
