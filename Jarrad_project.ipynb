{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 21:40:53.753236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 21:40:53.998100: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-27 21:40:55.163360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-27 21:40:55.163482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-27 21:40:55.163489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-27 21:40:56.736579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:56.766563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:56.766604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "import math\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os\n",
    "\n",
    "from keras.applications import VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, Xception, MobileNet, DenseNet121, NASNetMobile, EfficientNetB0, MobileNetV2, MobileNetV3Large\n",
    "from tensorflow.python.keras.layers import Conv2D, Flatten, Dropout, Dense, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0           414  0.8125    1.0    414.png\n",
      "1         17532  0.6875    1.0  17532.png\n",
      "2         16480  0.3125    0.0  16480.png\n",
      "3          6450  0.6875    0.0   6450.png\n",
      "4         12314  0.6250    0.0  12314.png\n",
      "...         ...     ...    ...        ...\n",
      "14821      9844  0.6875    1.0   9844.png\n",
      "14822     12367  0.5000    1.0  12367.png\n",
      "14823       343  0.9375    1.0    343.png\n",
      "14824      3838  0.6875    0.0   3838.png\n",
      "14825     13301  0.5000    1.0  13301.png\n",
      "\n",
      "[14826 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_size = [240, 320]\n",
    "\n",
    "# df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "# df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df.to_csv(\"training_norm_shuffle.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm_shuffle.csv')\n",
    "print(df)\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.6)]\n",
    "x_validate = df[int(len(df) * 0.6):int(len(df) * 0.8)]\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "# x_train = df[0:int(len(df) * 0.8)]\n",
    "# x_validate = df[int(len(df) * 0.8):]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8895 validated image filenames.\n",
      "Found 8895 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2966 validated image filenames.\n",
      "Found 2966 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shift = 0.1\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    # width_shift_range=shift,\n",
    "    # height_shift_range=shift\n",
    ")\n",
    "\n",
    "speed_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "speed_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "evaluate_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "speed_eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  file type\n",
      "0        1.png     1  png\n",
      "1        2.png     2  png\n",
      "2        3.png     3  png\n",
      "3        4.png     4  png\n",
      "4        5.png     5  png\n",
      "...        ...   ...  ...\n",
      "1015  1016.png  1016  png\n",
      "1016  1017.png  1017  png\n",
      "1017  1018.png  1018  png\n",
      "1018  1019.png  1019  png\n",
      "1019  1020.png  1020  png\n",
      "\n",
      "[1020 rows x 3 columns]\n",
      "Found 1020 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "filename = os.listdir(\"machine-learning-in-science-ii-2023/test_data/test_data\") \n",
    "\n",
    "df = pd.DataFrame(filename)\n",
    "df.columns = [\"filename\"]\n",
    "\n",
    "df[['file', 'type']] = df.filename.str.split(\".\", expand = True)\n",
    "df[\"file\"] = df[\"file\"].astype(str).astype(int)\n",
    "\n",
    "df.sort_values(by=['file'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_images = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=\"machine-learning-in-science-ii-2023/test_data/test_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 21:40:57.408694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 21:40:57.411913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:57.411982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:57.412003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:58.500775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:58.501248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:58.501266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-27 21:40:58.501300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-27 21:40:58.501343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "input_shape = [240, 320, 3]\n",
    "transfer = MobileNetV2(\n",
    "    input_shape=input_shape, \n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    classifier_activation=\"relu\"\n",
    ")\n",
    "\n",
    "for layer in transfer.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [],
   "source": [
    "# Speed CNN base\n",
    "speed_model = models.Sequential()\n",
    "\n",
    "speed_model.add(transfer)\n",
    "speed_model.build()\n",
    "        \n",
    "speed_model.add(layers.Conv2D(128, (3, 3), strides=(2,2), activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "\n",
    "speed_model.add(layers.Flatten()),\n",
    "\n",
    "speed_model.add(layers.Dense(128, activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "speed_model.add(layers.Dropout(0.2))\n",
    "\n",
    "speed_model.add(layers.Dense(64, activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "speed_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "speed_model.add(layers.Flatten())\n",
    "speed_model.add(layers.Dense(1,  activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle CNN base\n",
    "angle_model = models.Sequential()\n",
    "\n",
    "angle_model.add(transfer)\n",
    "angle_model.build()\n",
    "        \n",
    "angle_model.add(layers.Conv2D(128, (3, 3), strides=(2,2), activation='relu'))\n",
    "angle_model.add(layers.BatchNormalization())\n",
    "\n",
    "angle_model.add(layers.Flatten()),\n",
    "\n",
    "# model_1.add(layers.Dense(128, activation='relu'))\n",
    "angle_model.add(layers.Dense(128, activation='relu'))\n",
    "angle_model.add(layers.BatchNormalization())\n",
    "angle_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "angle_model.add(layers.Flatten())\n",
    "angle_model.add(layers.Dense(1,  activation='relu', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_model.build()\n",
    "angle_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEzHX-7ESeCl",
    "outputId": "b1ad1ed9-87ef-4a37-b392-59e9ebb807d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#speed_model.summary()\n",
    "#angle_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = speed_model.fit(\n",
    "#     speed_train_generator,\n",
    "#     batch_size=batch_size,\n",
    "#     validation_data=speed_val_generator,\n",
    "#     callbacks=[es],\n",
    "#     epochs=100\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = speed_model.evaluate(\n",
    "#     speed_eval_generator,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 21:41:12.362615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-27 21:41:16.073939: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-27 21:41:18.199377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-27 21:41:18.232764: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7ff6e8b375b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-27 21:41:18.232808: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-27 21:41:18.268907: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-27 21:41:18.539584: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-27 21:41:18.577251: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 51s 60ms/step - loss: 0.0840 - val_loss: 0.0200\n",
      "Epoch 2/100\n",
      "556/556 [==============================] - 30s 54ms/step - loss: 0.0164 - val_loss: 0.0099\n",
      "Epoch 3/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 4/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 5/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 6/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 7/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 8/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 9/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0055 - val_loss: 0.0103\n",
      "Epoch 10/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 11/100\n",
      "556/556 [==============================] - 28s 50ms/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 12/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 13/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 14/100\n",
      "556/556 [==============================] - 27s 48ms/step - loss: 0.0040 - val_loss: 0.0076\n",
      "Epoch 15/100\n",
      "556/556 [==============================] - 27s 48ms/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 16/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 17/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0037 - val_loss: 0.0084\n",
      "Epoch 18/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0035 - val_loss: 0.0137\n",
      "Epoch 19/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0032 - val_loss: 0.0077\n",
      "Epoch 20/100\n",
      "556/556 [==============================] - 26s 46ms/step - loss: 0.0033 - val_loss: 0.0069\n",
      "Epoch 21/100\n",
      "556/556 [==============================] - 27s 48ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 22/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0030 - val_loss: 0.0064\n",
      "Epoch 23/100\n",
      "556/556 [==============================] - 27s 48ms/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 24/100\n",
      "556/556 [==============================] - 27s 49ms/step - loss: 0.0029 - val_loss: 0.0081\n",
      "Epoch 25/100\n",
      "556/556 [==============================] - 27s 48ms/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 26/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 27/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0028 - val_loss: 0.0077\n",
      "Epoch 28/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 29/100\n",
      "556/556 [==============================] - 26s 47ms/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 30/100\n",
      "555/556 [============================>.] - ETA: 0s - loss: 0.0026Restoring model weights from the end of the best epoch: 10.\n",
      "556/556 [==============================] - 26s 46ms/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 30: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 83ms/step - loss: 0.0066\n"
     ]
    }
   ],
   "source": [
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_model.save(\"speed-model.h5\")\n",
    "angle_model.save(\"angle-model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 80ms/step\n",
      "32/32 [==============================] - 3s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "angle_prediction = angle_model.predict(test_images)\n",
    "speed_prediction = speed_model.predict(test_images)\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "submission = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "df = pd.DataFrame(submission)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11860</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.686453</td>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11861</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.751384</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.693253</td>\n",
       "      <td>0.068253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11863</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.623532</td>\n",
       "      <td>0.063968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11864</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.730291</td>\n",
       "      <td>0.042791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14821</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.708553</td>\n",
       "      <td>0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14822</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.433915</td>\n",
       "      <td>0.066085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14823</th>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.777668</td>\n",
       "      <td>0.159832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14824</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.794277</td>\n",
       "      <td>0.106777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.549592</td>\n",
       "      <td>0.049592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2966 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Train  Predicted  Difference\n",
       "11860  0.6875   0.686453    0.001047\n",
       "11861  0.7500   0.751384    0.001384\n",
       "11862  0.6250   0.693253    0.068253\n",
       "11863  0.6875   0.623532    0.063968\n",
       "11864  0.6875   0.730291    0.042791\n",
       "...       ...        ...         ...\n",
       "14821  0.6875   0.708553    0.021053\n",
       "14822  0.5000   0.433915    0.066085\n",
       "14823  0.9375   0.777668    0.159832\n",
       "14824  0.6875   0.794277    0.106777\n",
       "14825  0.5000   0.549592    0.049592\n",
       "\n",
       "[2966 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = abs(x_evaluate[\"angle\"] - angle_prediction)\n",
    "results = pd.DataFrame({\"Train\":x_evaluate[\"angle\"], \"Predicted\":angle_prediction, \"Difference\":diff})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Train\":x_evaluate[\"speed\"],\"Predicted\":b})\n",
    "#results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model = load_model(\"speed-model.h5\")\n",
    "angle_model = load_model(\"angle-model1.h5\")\n",
    "\n",
    "\n",
    "angle_transfer = angle_model.layers[0]\n",
    "angle_transfer.trainable = True\n",
    "\n",
    "for layer in angle_transfer.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "        \n",
    "angle_model.summary()\n",
    "\n",
    "\n",
    "speed_transfer = speed_model.layers[0]\n",
    "speed_transfer.trainable = True\n",
    "\n",
    "for layer in speed_transfer.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "speed_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speed_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0005,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history = speed_model.fit(\n",
    "    speed_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=speed_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_loss = speed_model.evaluate(\n",
    "    speed_eval_generator,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model.save(\"speed-model-fine-tuning.h5\")\n",
    "angle_model.save(\"angle-model-fine-tuning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_prediction = angle_model.predict(test_images)\n",
    "speed_prediction = speed_model.predict(test_images)\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "submission = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "df = pd.DataFrame(submission)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission-fine-tuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model-fine-tuning.hdf5\")\n",
    "plot_model(model, show_layer_names=True, show_shapes=True,show_layer_activations=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis2_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83badb9abfa833c8f944a253dee1819f5989bd8424f7fb8e0e95b6cecc08b674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
