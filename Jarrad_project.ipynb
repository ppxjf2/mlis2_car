{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from 'c:\\\\Users\\\\Jarrad\\\\anaconda3\\\\envs\\\\mlis2_car\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "  \n",
    "print(tf.version)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0             1  0.4375    0.0      1.png\n",
      "1             2  0.8125    1.0      2.png\n",
      "2             3  0.4375    1.0      3.png\n",
      "3             4  0.6250    1.0      4.png\n",
      "4             5  0.5000    0.0      5.png\n",
      "...         ...     ...    ...        ...\n",
      "13788     13794  0.6250    1.0  13794.png\n",
      "13789     13795  0.4375    1.0  13795.png\n",
      "13790     13796  0.5625    0.0  13796.png\n",
      "13791     13797  0.6250    0.0  13797.png\n",
      "13792     13798  0.6875    1.0  13798.png\n",
      "\n",
      "[13793 rows x 4 columns]\n",
      "Found 13798 files belonging to 1 classes.\n",
      "Using 11039 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_size = [240, 320]\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "#df['label'] = [df[\"angle\"], df[\"speed\"]]\n",
    "print(df)\n",
    "\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.8)]\n",
    "x_validate = df[int(len(df) * 0.8):]\n",
    "\n",
    "training_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"machine-learning-in-science-ii-2023/training_data\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "# testing = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     \"machine-learning-in-science-ii-2023/testing_data/testing_data\",\n",
    "#     image_size=img_size,\n",
    "#     batch_size=batch_size,\n",
    "# )\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     zoom_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     width_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     fill_mode='nearest')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 10))\n",
    "# for images, labels in training_images.take(1):\n",
    "#     for i in range(16):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         #plt.title(training.class_names[labels[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11034 validated image filenames.\n",
      "Found 2759 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    batch_size=16,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    class_mode='other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "\n",
    "# CNN base\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten()),\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.7))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEzHX-7ESeCl",
    "outputId": "b1ad1ed9-87ef-4a37-b392-59e9ebb807d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 238, 318, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 238, 318, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 119, 159, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 117, 157, 16)      4624      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 117, 157, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 58, 78, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 76, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 54, 74, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 54, 74, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 27, 37, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 25, 35, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 25, 35, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 15, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 10, 15, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4480)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1147136   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,279,953\n",
      "Trainable params: 1,278,705\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "190/690 [=======>......................] - ETA: 6:57 - loss: 0.2170"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 32ms/step - loss: 1.2952 - accuracy: 0.6904 0s - loss: 1.3117 - ac\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "    testing,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 17ms/step - loss: 1.2952 - accuracy: 0.6904\n",
      "80/80 [==============================] - 1s 16ms/step\n",
      "[2 2 0 ... 1 3 2]\n",
      "[2 2 0 ... 3 3 2]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    MildDemented       0.62      0.36      0.45       179\n",
      "ModerateDemented       0.67      0.17      0.27        12\n",
      "     NonDemented       0.68      0.91      0.78       640\n",
      "VeryMildDemented       0.76      0.52      0.61       448\n",
      "\n",
      "        accuracy                           0.69      1279\n",
      "       macro avg       0.68      0.49      0.53      1279\n",
      "    weighted avg       0.70      0.69      0.67      1279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = tf.keras.models.load_model('secondModel.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    testing,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "predict_model = model.predict(testing, verbose =1)\n",
    "\n",
    "y = np.concatenate([y for x, y in testing], axis=0)\n",
    "true = np.argmax(y, axis = 1)\n",
    "\n",
    "print(true)\n",
    "predict_model = np.argmax(predict_model, axis = 1)\n",
    "print(predict_model)\n",
    "\n",
    "print(classification_report(true, predict_model, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis2_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83badb9abfa833c8f944a253dee1819f5989bd8424f7fb8e0e95b6cecc08b674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
