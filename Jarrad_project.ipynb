{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 16:52:17.305428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 16:52:17.544364: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-31 16:52:18.795211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-31 16:52:18.795357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jarrad_foley135/miniconda3/envs/mlis_cw_car/lib/\n",
      "2023-03-31 16:52:18.795364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-31 16:52:20.518758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 16:52:20.553147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 16:52:20.553215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "import math\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os\n",
    "\n",
    "from keras.applications import VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, Xception, MobileNet, DenseNet121, NASNetMobile, EfficientNetB0, MobileNetV2, MobileNetV3Large, ResNet152\n",
    "from tensorflow.python.keras.layers import Conv2D, Flatten, Dropout, Dense, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import model_from_json\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0           414  0.8125    1.0    414.png\n",
      "1         17532  0.6875    1.0  17532.png\n",
      "2         16480  0.3125    0.0  16480.png\n",
      "3          6450  0.6875    0.0   6450.png\n",
      "4         12314  0.6250    0.0  12314.png\n",
      "...         ...     ...    ...        ...\n",
      "14821      9844  0.6875    1.0   9844.png\n",
      "14822     12367  0.5000    1.0  12367.png\n",
      "14823       343  0.9375    1.0    343.png\n",
      "14824      3838  0.6875    0.0   3838.png\n",
      "14825     13301  0.5000    1.0  13301.png\n",
      "\n",
      "[14826 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "# df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df.to_csv(\"training_norm_shuffle.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm_shuffle.csv')\n",
    "print(df)\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.6)]\n",
    "x_validate = df[int(len(df) * 0.6):int(len(df) * 0.8)]\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "# x_train = df[0:int(len(df) * 0.8)]\n",
    "# x_validate = df[int(len(df) * 0.8):]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8895 validated image filenames.\n",
      "Found 8895 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2965 validated image filenames.\n",
      "Found 2966 validated image filenames.\n",
      "Found 2966 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_size = [240, 320]\n",
    "shift = 0.1\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=shift,\n",
    "    height_shift_range=shift,\n",
    "    brightness_range=(0.75, 1.25)\n",
    "    \n",
    ")\n",
    "\n",
    "speed_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "speed_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "evaluate_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "speed_eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"speed\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "angle_eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename  file type\n",
      "0        1.png     1  png\n",
      "1        2.png     2  png\n",
      "2        3.png     3  png\n",
      "3        4.png     4  png\n",
      "4        5.png     5  png\n",
      "...        ...   ...  ...\n",
      "1015  1016.png  1016  png\n",
      "1016  1017.png  1017  png\n",
      "1017  1018.png  1018  png\n",
      "1018  1019.png  1019  png\n",
      "1019  1020.png  1020  png\n",
      "\n",
      "[1020 rows x 3 columns]\n",
      "Found 1020 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "filename = os.listdir(\"machine-learning-in-science-ii-2023/test_data/test_data\") \n",
    "\n",
    "df = pd.DataFrame(filename)\n",
    "df.columns = [\"filename\"]\n",
    "\n",
    "df[['file', 'type']] = df.filename.str.split(\".\", expand = True)\n",
    "df[\"file\"] = df[\"file\"].astype(str).astype(int)\n",
    "\n",
    "df.sort_values(by=['file'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df)\n",
    "submission_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "submission_images = submission_datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=\"machine-learning-in-science-ii-2023/test_data/test_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "input_shape = [240, 320, 3]\n",
    "transfer = MobileNetV2(\n",
    "    input_shape=input_shape, \n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    classifier_activation=\"relu\"\n",
    ")\n",
    "\n",
    "for layer in transfer.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 4, 256)         2949376   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 3, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                196672    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,405,377\n",
      "Trainable params: 3,146,753\n",
      "Non-trainable params: 2,258,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Speed CNN base\n",
    "speed_model = models.Sequential()\n",
    "\n",
    "speed_model.add(transfer)\n",
    "speed_model.build()\n",
    "        \n",
    "speed_model.add(layers.Conv2D(256, (3, 3), strides=(2,2), activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "\n",
    "speed_model.add(layers.Flatten()),\n",
    "\n",
    "# speed_model.add(layers.Dense(128, activation='relu'))\n",
    "# speed_model.add(layers.BatchNormalization())\n",
    "# speed_model.add(layers.Dropout(0.2))\n",
    "\n",
    "speed_model.add(layers.Dense(64, activation='relu'))\n",
    "speed_model.add(layers.BatchNormalization())\n",
    "speed_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "speed_model.add(layers.Flatten())\n",
    "speed_model.add(layers.Dense(1,  activation='sigmoid'))\n",
    "\n",
    "speed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 4, 64)          737344    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 3, 4, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 768)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                49216     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,045,121\n",
      "Trainable params: 786,881\n",
      "Non-trainable params: 2,258,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Angle CNN base\n",
    "angle_model = models.Sequential()\n",
    "\n",
    "angle_model.add(transfer)\n",
    "angle_model.build()\n",
    "        \n",
    "angle_model.add(layers.Conv2D(256, (3, 3), strides=(2,2), activation='relu'))\n",
    "angle_model.add(layers.BatchNormalization())\n",
    "\n",
    "angle_model.add(layers.Flatten()),\n",
    "\n",
    "# model_1.add(layers.Dense(128, activation='relu'))\n",
    "angle_model.add(layers.Dense(64, activation='relu'))\n",
    "angle_model.add(layers.BatchNormalization())\n",
    "angle_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "angle_model.add(layers.Flatten())\n",
    "angle_model.add(layers.Dense(1,  activation='relu'))\n",
    "\n",
    "angle_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_model.build()\n",
    "#angle_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 109s 377ms/step - loss: 0.0414 - val_loss: 0.0242\n"
     ]
    }
   ],
   "source": [
    "history = speed_model.fit(\n",
    "    speed_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=speed_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 90ms/step - loss: 0.0247\n"
     ]
    }
   ],
   "source": [
    "test_loss = speed_model.evaluate(\n",
    "    speed_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "278/278 [==============================] - 113s 395ms/step - loss: 0.3157 - val_loss: 0.1431\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 102s 366ms/step - loss: 0.1442 - val_loss: 0.0676\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 108s 390ms/step - loss: 0.0773 - val_loss: 0.0412\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 116s 416ms/step - loss: 0.0461 - val_loss: 0.0235\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 118s 424ms/step - loss: 0.0289 - val_loss: 0.0139\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 117s 422ms/step - loss: 0.0167 - val_loss: 0.0085\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 116s 418ms/step - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 116s 419ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 112s 403ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 111s 400ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 112s 404ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 119s 427ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 119s 427ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 118s 423ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 111s 399ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 119s 427ms/step - loss: 0.0075 - val_loss: 0.0237\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 120s 430ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 119s 429ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 121s 434ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 121s 434ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 120s 433ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 121s 436ms/step - loss: 0.0064 - val_loss: 0.1431\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 119s 429ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 116s 416ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 118s 424ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 118s 423ms/step - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 115s 414ms/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 117s 419ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 117s 419ms/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 118s 423ms/step - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 119s 428ms/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 120s 430ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 117s 420ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 35/100\n",
      "278/278 [==============================] - 118s 425ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 36/100\n",
      "278/278 [==============================] - 119s 426ms/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 37/100\n",
      "278/278 [==============================] - 105s 379ms/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 38/100\n",
      "278/278 [==============================] - 114s 409ms/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 39/100\n",
      "278/278 [==============================] - 117s 422ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 40/100\n",
      "278/278 [==============================] - 119s 427ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 41/100\n",
      "278/278 [==============================] - 121s 434ms/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 42/100\n",
      "278/278 [==============================] - 120s 431ms/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 43/100\n",
      "278/278 [==============================] - 122s 438ms/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 44/100\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0048Restoring model weights from the end of the best epoch: 24.\n",
      "278/278 [==============================] - 121s 434ms/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 44: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 10s 105ms/step - loss: 0.0087\n"
     ]
    }
   ],
   "source": [
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_model.save(\"speed-model.h5\")\n",
    "angle_model.save(\"angle-model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 110ms/step\n",
      "32/32 [==============================] - 4s 91ms/step\n"
     ]
    }
   ],
   "source": [
    "angle_prediction = angle_model.predict(submission_images)\n",
    "speed_prediction = speed_model.predict(submission_images)\n",
    "\n",
    "speed_prediction = speed_prediction.flatten()\n",
    "angle_prediction = angle_prediction.flatten()\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "submission = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "df = pd.DataFrame(submission)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv', index_label=\"image_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m angle_prediction \u001b[39m=\u001b[39m angle_model\u001b[39m.\u001b[39;49mpredict(x_evaluate)\n\u001b[1;32m      2\u001b[0m speed_prediction \u001b[39m=\u001b[39m speed_model\u001b[39m.\u001b[39mpredict(x_evaluate)\n\u001b[1;32m      4\u001b[0m diff \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(x_evaluate[\u001b[39m\"\u001b[39m\u001b[39mangle\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m-\u001b[39m angle_prediction)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/mlis_cw_car/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "angle_prediction = angle_model.predict(x_evaluate)\n",
    "speed_prediction = speed_model.predict(x_evaluate)\n",
    "\n",
    "diff = abs(x_evaluate[\"angle\"] - angle_prediction)\n",
    "results = pd.DataFrame({\"Train\":x_evaluate[\"angle\"], \"Predicted\":angle_prediction, \"Difference\":diff})\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Train\":x_evaluate[\"speed\"],\"Predicted\":speed_prediction})\n",
    "#results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 4, 256)         2949376   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                196672    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,405,377\n",
      "Trainable params: 4,508,673\n",
      "Non-trainable params: 896,704\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 4, 256)         2949376   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                196672    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,405,377\n",
      "Trainable params: 4,508,673\n",
      "Non-trainable params: 896,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speed_model = load_model(\"angle-model.h5\")\n",
    "angle_model = load_model(\"angle-model.h5\")\n",
    "\n",
    "\n",
    "angle_transfer = angle_model.layers[0]\n",
    "angle_transfer.trainable = True\n",
    "\n",
    "for layer in angle_transfer.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "        \n",
    "angle_model.summary()\n",
    "\n",
    "\n",
    "speed_transfer = speed_model.layers[0]\n",
    "speed_transfer.trainable = True\n",
    "\n",
    "for layer in speed_transfer.layers[:-25]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "speed_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speed_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0005,\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "278/278 [==============================] - 107s 384ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 2/300\n",
      "278/278 [==============================] - 107s 384ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 3/300\n",
      "278/278 [==============================] - 107s 386ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 4/300\n",
      "278/278 [==============================] - 107s 383ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 5/300\n",
      "278/278 [==============================] - 111s 398ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 6/300\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0056"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = speed_model.fit(\n",
    "    speed_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=speed_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_loss = speed_model.evaluate(\n",
    "    speed_eval_generator,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model.save(\"speed-model-fine-tuning.h5\")\n",
    "angle_model.save(\"angle-model-fine-tuning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_prediction = angle_model.predict(submission_images)\n",
    "speed_prediction = speed_model.predict(submission_images)\n",
    "\n",
    "speed_prediction = speed_prediction.flatten()\n",
    "angle_prediction = angle_prediction.flatten()\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "submission = {\"angle\":angle_prediction , \"speed\":speed_prediction}\n",
    "\n",
    "df = pd.DataFrame(submission)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission-fine-tuning.csv', index_label=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model-fine-tuning.hdf5\")\n",
    "plot_model(model, show_layer_names=True, show_shapes=True,show_layer_activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Image File ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_model = load_model(\"speed-model.h5\")\n",
    "angle_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "x_all = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "x_all['filename'] = x_all[\"image_id\"].astype(str) + \".png\"\n",
    "\n",
    "clean_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "clean_generator = clean_datagen.flow_from_dataframe(\n",
    "    dataframe=x_all,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None)\n",
    "\n",
    "angle_prediction = angle_model.predict(clean_generator)\n",
    "speed_prediction = speed_model.predict(clean_generator)\n",
    "\n",
    "# predict = model.predict(clean_generator)\n",
    "\n",
    "# angle_prediction = predict[:,0]\n",
    "# speed_prediction = predict[:,1]\n",
    "\n",
    "diff = abs(x_all[\"angle\"] - angle_prediction)\n",
    "\n",
    "speed_prediction += 0.5\n",
    "speed_prediction = np.floor(speed_prediction)\n",
    "\n",
    "correct = (x_all[\"speed\"] == speed_prediction)\n",
    "\n",
    "clean_data = {\n",
    "    \"image_id\":x_all[\"image_id\"], \n",
    "    \"Actual Angle\":x_all[\"angle\"], \n",
    "    \"Predicted Angle\":angle_prediction, \n",
    "    \"Angle Difference\":diff, \n",
    "    \"Actual Speed\":x_all[\"speed\"], \n",
    "    \"Predicted Speed\":speed_prediction,\n",
    "    \"Correct?\":correct\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(clean_data)\n",
    "df.index += 1 \n",
    "#df.to_csv('clean-results.csv', index_label=\"image_id\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run other models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 5s 131ms/step\n",
      "32/32 [==============================] - 4s 94ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n"
     ]
    }
   ],
   "source": [
    "#angle_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "best_speed_model = load_model(\"best-sakthi.hdf5\")\n",
    "best_angle_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "sakthi_model = load_model(\"sakthi.hdf5\")\n",
    "\n",
    "best_speed_prediction = best_speed_model.predict(submission_images)\n",
    "best_angle_prediction = best_angle_model.predict(submission_images)\n",
    "sakthi_prediction = sakthi_model.predict(submission_images)\n",
    "\n",
    "# speed_prediction = speed_prediction[0]\n",
    "\n",
    "best_speed_prediction = best_speed_prediction.flatten()\n",
    "best_angle_prediction = best_angle_prediction.flatten()\n",
    "\n",
    "# sakthi_prediction = sakthi_prediction.flatten()\n",
    "\n",
    "\n",
    "\n",
    "sakthi_angle = sakthi_prediction[1]\n",
    "sakthi_speed = sakthi_prediction[0]\n",
    "\n",
    "sakthi_angle = sakthi_angle.flatten()\n",
    "sakthi_speed = sakthi_speed.flatten()\n",
    "\n",
    "\n",
    "sakthi_speed += 0.5\n",
    "sakthi_speed = np.floor(sakthi_speed)\n",
    "\n",
    "diff = abs(best_angle_prediction - sakthi_angle)\n",
    "\n",
    "best_speed_prediction += 0.5\n",
    "best_speed_prediction = np.floor(best_speed_prediction)\n",
    "\n",
    "match = (best_speed_prediction == sakthi_speed)\n",
    "\n",
    "# validate = {\n",
    "#     \"Best Angle\":best_angle_prediction, \n",
    "#     \"Sakthi Angle\":sakthi_angle, \n",
    "#     \"Angle Difference\":diff, \n",
    "#     \"Best Speed\":best_speed_prediction, \n",
    "#     \"Sakthi Speed\":sakthi_speed,\n",
    "#     \"Match\":match\n",
    "# }\n",
    "validate = {\"angle\":sakthi_angle, \"speed\":best_speed_prediction}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(validate)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission-alt.csv', index_label=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 81ms/step - loss: 0.0058\n"
     ]
    }
   ],
   "source": [
    "speed_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "\n",
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Testing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run(con:int, dense:int, batch: int, epoch:int):\n",
    "    \n",
    "    input_shape = [240, 320, 3]\n",
    "    transfer = ResNet152(\n",
    "        input_shape=input_shape, \n",
    "        include_top=False, \n",
    "        weights='imagenet',\n",
    "        classifier_activation=\"relu\"\n",
    "    )\n",
    "\n",
    "    for layer in transfer.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Angle CNN base\n",
    "    angle_model = models.Sequential()\n",
    "\n",
    "    angle_model.add(transfer)\n",
    "    angle_model.build()\n",
    "            \n",
    "    angle_model.add(layers.Conv2D(con, (3, 3), strides=(2,2), activation='relu'))\n",
    "    angle_model.add(layers.BatchNormalization())\n",
    "\n",
    "    angle_model.add(layers.Flatten()),\n",
    "\n",
    "    angle_model.add(layers.Dense(dense, activation='relu'))\n",
    "    angle_model.add(layers.BatchNormalization())\n",
    "    angle_model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Output layer\n",
    "    angle_model.add(layers.Flatten())\n",
    "    angle_model.add(layers.Dense(1,  activation='relu'))\n",
    "\n",
    "    ## Compile\n",
    "    angle_model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.005),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.001,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = angle_model.fit(\n",
    "        angle_train_generator,\n",
    "        batch_size=batch,\n",
    "        validation_data=angle_val_generator,\n",
    "        callbacks=[es],\n",
    "        epochs=epoch\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    return angle_model, history\n",
    "\n",
    "def model_run1(batch: int, epoch:int, angle_model):\n",
    "    ## Compile\n",
    "    angle_model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = angle_model.fit(\n",
    "        angle_train_generator,\n",
    "        batch_size=batch,\n",
    "        validation_data=angle_val_generator,\n",
    "        callbacks=[es],\n",
    "        epochs=epoch\n",
    "    )\n",
    "\n",
    "    return angle_model, history\n",
    "\n",
    "def model_fine_tuning(angle_model):\n",
    "    \n",
    "    angle_transfer = angle_model.layers[0]\n",
    "    angle_transfer.trainable = True\n",
    "\n",
    "    for layer in angle_transfer.layers[:-25]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    angle_model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0005,\n",
    "        patience=30,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = angle_model.fit(\n",
    "        angle_train_generator,\n",
    "        batch_size=8,\n",
    "        validation_data=angle_val_generator,\n",
    "        callbacks=[es],\n",
    "        epochs=300\n",
    "    )\n",
    "    \n",
    "    return angle_model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8895 validated image filenames.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 16:57:02.577025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-31 16:57:04.114185: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-31 16:57:06.550635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-31 16:57:06.577592: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6c32610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-31 16:57:06.577630: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-31 16:57:06.595954: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-31 16:57:06.833593: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-31 16:57:06.864745: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 146s 482ms/step - loss: 0.1297 - val_loss: 0.0133\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 132s 475ms/step - loss: 0.0149 - val_loss: 0.0097\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 131s 469ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 134s 482ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 130s 467ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 128s 460ms/step - loss: 0.0102 - val_loss: 0.0378\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 124s 447ms/step - loss: 0.0099 - val_loss: 0.0206\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 122s 440ms/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 122s 439ms/step - loss: 0.0093 - val_loss: 0.0230\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 123s 441ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 122s 439ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 132s 474ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0089Restoring model weights from the end of the best epoch: 3.\n",
      "278/278 [==============================] - 126s 452ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 13: early stopping\n",
      "93/93 [==============================] - 22s 237ms/step - loss: 0.0079\n",
      "Found 8895 validated image filenames.\n",
      "Epoch 1/100\n",
      "1112/1112 [==============================] - 145s 122ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "1112/1112 [==============================] - 134s 121ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 3/100\n",
      "1112/1112 [==============================] - 135s 121ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 4/100\n",
      "1112/1112 [==============================] - 135s 121ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 5/100\n",
      "1112/1112 [==============================] - 132s 119ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 6/100\n",
      "1112/1112 [==============================] - 135s 121ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 7/100\n",
      "1112/1112 [==============================] - 131s 118ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 8/100\n",
      "1112/1112 [==============================] - 133s 120ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 9/100\n",
      "1112/1112 [==============================] - 141s 126ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 10/100\n",
      "1112/1112 [==============================] - 133s 119ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "1112/1112 [==============================] - 133s 120ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 12/100\n",
      "1112/1112 [==============================] - 135s 121ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "1112/1112 [==============================] - 137s 123ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 14/100\n",
      "1112/1112 [==============================] - 135s 121ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 15/100\n",
      "1112/1112 [==============================] - 138s 124ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 16/100\n",
      "1112/1112 [==============================] - 137s 123ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 17/100\n",
      "1112/1112 [==============================] - 137s 123ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 18/100\n",
      "1112/1112 [==============================] - 139s 125ms/step - loss: 0.0099 - val_loss: 0.0072\n",
      "Epoch 19/100\n",
      "1112/1112 [==============================] - 134s 121ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 20/100\n",
      "1112/1112 [==============================] - 136s 122ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 21/100\n",
      "1112/1112 [==============================] - 3988s 4s/step - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 22/100\n",
      "1112/1112 [==============================] - 137s 123ms/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 23/100\n",
      "1112/1112 [==============================] - 135s 122ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 24/100\n",
      "1112/1112 [==============================] - 132s 118ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 25/100\n",
      "1112/1112 [==============================] - 131s 118ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 26/100\n",
      "1112/1112 [==============================] - 133s 120ms/step - loss: 0.0096 - val_loss: 0.0482\n",
      "Epoch 27/100\n",
      "1112/1112 [==============================] - 133s 120ms/step - loss: 0.0097 - val_loss: 0.0243\n",
      "Epoch 28/100\n",
      "1112/1112 [==============================] - 133s 120ms/step - loss: 0.0096 - val_loss: 0.3749\n",
      "Epoch 29/100\n",
      "1112/1112 [==============================] - 134s 120ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 30/100\n",
      "1112/1112 [==============================] - 162s 146ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 31/100\n",
      "1112/1112 [==============================] - 161s 145ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 32/100\n",
      "1112/1112 [==============================] - 153s 137ms/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 33/100\n",
      "1112/1112 [==============================] - ETA: 0s - loss: 0.0094Restoring model weights from the end of the best epoch: 13.\n",
      "1112/1112 [==============================] - 153s 137ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 33: early stopping\n",
      "93/93 [==============================] - 23s 245ms/step - loss: 0.0066\n",
      "Epoch 1/300\n",
      "1112/1112 [==============================] - 167s 141ms/step - loss: 0.0111 - val_loss: 0.0718\n",
      "Epoch 2/300\n",
      "1112/1112 [==============================] - 156s 140ms/step - loss: 0.0104 - val_loss: 0.0165\n",
      "Epoch 3/300\n",
      "1112/1112 [==============================] - 151s 136ms/step - loss: 0.0101 - val_loss: 0.0243\n",
      "Epoch 4/300\n",
      "1112/1112 [==============================] - 154s 139ms/step - loss: 0.0099 - val_loss: 0.0213\n",
      "Epoch 5/300\n",
      "1112/1112 [==============================] - 158s 142ms/step - loss: 0.0099 - val_loss: 0.0254\n",
      "Epoch 6/300\n",
      "1112/1112 [==============================] - 142s 127ms/step - loss: 0.0095 - val_loss: 0.0861\n",
      "Epoch 7/300\n",
      "1112/1112 [==============================] - 167s 150ms/step - loss: 0.0095 - val_loss: 0.0528\n",
      "Epoch 8/300\n",
      "1112/1112 [==============================] - 162s 146ms/step - loss: 0.0094 - val_loss: 0.0810\n",
      "Epoch 9/300\n",
      "1112/1112 [==============================] - 154s 138ms/step - loss: 0.0094 - val_loss: 0.0601\n",
      "Epoch 10/300\n",
      "1112/1112 [==============================] - 147s 132ms/step - loss: 0.0093 - val_loss: 0.0491\n",
      "Epoch 11/300\n",
      "1112/1112 [==============================] - 155s 140ms/step - loss: 0.0092 - val_loss: 0.0381\n",
      "Epoch 12/300\n",
      "1112/1112 [==============================] - 162s 145ms/step - loss: 0.0091 - val_loss: 0.1366\n",
      "Epoch 13/300\n",
      "1112/1112 [==============================] - 158s 142ms/step - loss: 0.0090 - val_loss: 0.0259\n",
      "Epoch 14/300\n",
      "1112/1112 [==============================] - 145s 130ms/step - loss: 0.0089 - val_loss: 0.0179\n",
      "Epoch 15/300\n",
      "1112/1112 [==============================] - 142s 128ms/step - loss: 0.0088 - val_loss: 0.0126\n",
      "Epoch 16/300\n",
      "1112/1112 [==============================] - 144s 129ms/step - loss: 0.0089 - val_loss: 0.1098\n",
      "Epoch 17/300\n",
      "1112/1112 [==============================] - 155s 140ms/step - loss: 0.0087 - val_loss: 0.1860\n",
      "Epoch 18/300\n",
      "1112/1112 [==============================] - 152s 137ms/step - loss: 0.0087 - val_loss: 0.0854\n",
      "Epoch 19/300\n",
      "1112/1112 [==============================] - 167s 150ms/step - loss: 0.0087 - val_loss: 0.0648\n",
      "Epoch 20/300\n",
      "1112/1112 [==============================] - 157s 141ms/step - loss: 0.0085 - val_loss: 0.0810\n",
      "Epoch 21/300\n",
      "1112/1112 [==============================] - 154s 139ms/step - loss: 0.0085 - val_loss: 0.0234\n",
      "Epoch 22/300\n",
      "1112/1112 [==============================] - 144s 129ms/step - loss: 0.0085 - val_loss: 0.0594\n",
      "Epoch 23/300\n",
      "1112/1112 [==============================] - 149s 134ms/step - loss: 0.0085 - val_loss: 0.0323\n",
      "Epoch 24/300\n",
      "1112/1112 [==============================] - 161s 144ms/step - loss: 0.0084 - val_loss: 0.0605\n",
      "Epoch 25/300\n",
      "1112/1112 [==============================] - 153s 138ms/step - loss: 0.0084 - val_loss: 0.0197\n",
      "Epoch 26/300\n",
      "1112/1112 [==============================] - 152s 136ms/step - loss: 0.0083 - val_loss: 0.1557\n",
      "Epoch 27/300\n",
      "1112/1112 [==============================] - 149s 134ms/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 28/300\n",
      "1112/1112 [==============================] - 151s 136ms/step - loss: 0.0083 - val_loss: 0.0581\n",
      "Epoch 29/300\n",
      "1112/1112 [==============================] - 151s 136ms/step - loss: 0.0082 - val_loss: 0.1116\n",
      "Epoch 30/300\n",
      "1112/1112 [==============================] - 147s 132ms/step - loss: 0.0082 - val_loss: 0.3211\n",
      "Epoch 31/300\n",
      "1112/1112 [==============================] - 152s 137ms/step - loss: 0.0081 - val_loss: 0.4717\n",
      "Epoch 32/300\n",
      "1112/1112 [==============================] - 149s 134ms/step - loss: 0.0081 - val_loss: 0.4959\n",
      "Epoch 33/300\n",
      "1112/1112 [==============================] - 151s 135ms/step - loss: 0.0081 - val_loss: 0.2838\n",
      "Epoch 34/300\n",
      "1112/1112 [==============================] - 148s 133ms/step - loss: 0.0080 - val_loss: 0.3123\n",
      "Epoch 35/300\n",
      "1112/1112 [==============================] - 153s 138ms/step - loss: 0.0080 - val_loss: 0.2505\n",
      "Epoch 36/300\n",
      "1112/1112 [==============================] - 159s 143ms/step - loss: 0.0079 - val_loss: 0.5252\n",
      "Epoch 37/300\n",
      "1112/1112 [==============================] - 155s 139ms/step - loss: 0.0079 - val_loss: 0.0530\n",
      "Epoch 38/300\n",
      "1112/1112 [==============================] - 155s 140ms/step - loss: 0.0079 - val_loss: 0.3979\n",
      "Epoch 39/300\n",
      "1112/1112 [==============================] - 155s 140ms/step - loss: 0.0078 - val_loss: 0.0579\n",
      "Epoch 40/300\n",
      "1112/1112 [==============================] - 154s 139ms/step - loss: 0.0078 - val_loss: 0.1215\n",
      "Epoch 41/300\n",
      "1112/1112 [==============================] - 158s 142ms/step - loss: 0.0079 - val_loss: 0.1242\n",
      "Epoch 42/300\n",
      "1112/1112 [==============================] - 156s 140ms/step - loss: 0.0077 - val_loss: 0.8036\n",
      "Epoch 43/300\n",
      "1112/1112 [==============================] - 157s 141ms/step - loss: 0.0077 - val_loss: 0.2462\n",
      "Epoch 44/300\n",
      "1112/1112 [==============================] - 159s 142ms/step - loss: 0.0077 - val_loss: 0.1996\n",
      "Epoch 45/300\n",
      "1112/1112 [==============================] - 157s 141ms/step - loss: 0.0076 - val_loss: 0.0973\n",
      "Epoch 46/300\n",
      "1112/1112 [==============================] - 160s 144ms/step - loss: 0.0077 - val_loss: 0.0727\n",
      "Epoch 47/300\n",
      "1112/1112 [==============================] - 158s 142ms/step - loss: 0.0076 - val_loss: 0.1725\n",
      "Epoch 48/300\n",
      "1112/1112 [==============================] - 167s 150ms/step - loss: 0.0077 - val_loss: 0.1150\n",
      "Epoch 49/300\n",
      "1112/1112 [==============================] - 154s 139ms/step - loss: 0.0075 - val_loss: 0.1708\n",
      "Epoch 50/300\n",
      "1112/1112 [==============================] - 159s 143ms/step - loss: 0.0075 - val_loss: 0.3291\n",
      "Epoch 51/300\n",
      "1112/1112 [==============================] - 157s 141ms/step - loss: 0.0075 - val_loss: 0.1514\n",
      "Epoch 52/300\n",
      "1112/1112 [==============================] - 155s 139ms/step - loss: 0.0076 - val_loss: 0.3037\n",
      "Epoch 53/300\n",
      "1112/1112 [==============================] - 158s 142ms/step - loss: 0.0073 - val_loss: 0.2032\n",
      "Epoch 54/300\n",
      "1112/1112 [==============================] - 156s 140ms/step - loss: 0.0075 - val_loss: 0.7688\n",
      "Epoch 55/300\n",
      "1112/1112 [==============================] - 155s 139ms/step - loss: 0.0074 - val_loss: 0.7030\n",
      "Epoch 56/300\n",
      "1112/1112 [==============================] - 154s 138ms/step - loss: 0.0073 - val_loss: 0.0936\n",
      "Epoch 57/300\n",
      "1112/1112 [==============================] - ETA: 0s - loss: 0.0073Restoring model weights from the end of the best epoch: 27.\n",
      "1112/1112 [==============================] - 153s 137ms/step - loss: 0.0073 - val_loss: 0.0681\n",
      "Epoch 57: early stopping\n",
      "93/93 [==============================] - 23s 247ms/step - loss: 0.0169\n"
     ]
    }
   ],
   "source": [
    "conv = [128] #,32,64,128,256,512]\n",
    "dense = [64] #[64,128,256,512]\n",
    "for i in range(len(conv)):\n",
    "    for j in range(len(dense)):\n",
    "\n",
    "        angle_train_generator = training_datagen.flow_from_dataframe(\n",
    "            dataframe=x_train,\n",
    "            directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "            x_col=\"filename\",\n",
    "            y_col=\"angle\",\n",
    "            target_size=img_size,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            class_mode='other')\n",
    "        \n",
    "        angle_model, history = model_run(conv[i], dense[j], 32, 100)\n",
    "        \n",
    "        loss = angle_model.evaluate(\n",
    "            angle_eval_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        angle_model.save(\"model_last.h5\")\n",
    "        \n",
    "        \n",
    "        angle_train_generator = training_datagen.flow_from_dataframe(\n",
    "            dataframe=x_train,\n",
    "            directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "            x_col=\"filename\",\n",
    "            y_col=\"angle\",\n",
    "            target_size=img_size,\n",
    "            batch_size=8,\n",
    "            shuffle=False,\n",
    "            class_mode='other')\n",
    "        \n",
    "        angle_model, history = model_run1(8, 100, angle_model)\n",
    "        \n",
    "        angle_model.save(\"model_last-2.h5\")\n",
    "\n",
    "        \n",
    "        loss1 = angle_model.evaluate(\n",
    "            angle_eval_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        angle_model, history = model_fine_tuning(angle_model)\n",
    "        \n",
    "        extra_loss = angle_model.evaluate(\n",
    "            angle_eval_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        angle_model.save(\"model_last-3.h5\")\n",
    "\n",
    "        \n",
    "        df = pd.DataFrame({\"conv\":conv[i], \"dense\":dense[j],\"loss\":loss, \"loss1\":loss1, \"fine tuning\":extra_loss}, index=[0])\n",
    "        df.to_csv('results.csv', mode='a', header=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining on new data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image_id   angle  speed   filename\n",
      "0        19246  0.5625      1  19246.png\n",
      "1        18040  0.5625      1  18040.png\n",
      "2        18650  0.5000      1  18650.png\n",
      "3        19161  0.2500      1  19161.png\n",
      "4        18281  0.2500      1  18281.png\n",
      "...        ...     ...    ...        ...\n",
      "1357     18592  0.3750      1  18592.png\n",
      "1358     18165  0.1875      1  18165.png\n",
      "1359     19264  0.6875      1  19264.png\n",
      "1360     18405  0.1875      1  18405.png\n",
      "1361     18458  0.5000      1  18458.png\n",
      "\n",
      "[1362 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(r'machine-learning-in-science-ii-2023/new_data.csv')\n",
    "# df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df.to_csv(\"new_data_shuffle.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/new_data_shuffle.csv')\n",
    "print(df)\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.6)]\n",
    "x_validate = df[int(len(df) * 0.6):int(len(df) * 0.8)]\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "# x_train = df[0:int(len(df) * 0.8)]\n",
    "# x_validate = df[int(len(df) * 0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 817 validated image filenames.\n",
      "Found 272 validated image filenames.\n",
      "Found 273 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_size = [240, 320]\n",
    "shift = 0.1\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=shift,\n",
    "    height_shift_range=shift\n",
    ")\n",
    "\n",
    "angle_train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/new_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "angle_val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/new_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"angle\",\n",
    "    target_size=img_size,\n",
    "    shuffle=False,\n",
    "    class_mode='other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "angle_model = load_model(\"angle-model.h5\")\n",
    "\n",
    "angle_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 21:15:35.622126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-30 21:15:37.192246: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-30 21:15:39.064207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-30 21:15:39.097990: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f57b4b5b7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-30 21:15:39.098039: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-30 21:15:39.143470: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-30 21:15:39.438690: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-03-30 21:15:39.473540: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 20s 431ms/step - loss: 0.0219 - val_loss: 0.0224\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 10s 380ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 10s 382ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 10s 399ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 10s 398ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 10s 371ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 10s 381ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 10s 369ms/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 10s 383ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 10s 391ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 10s 399ms/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 10s 392ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 12s 443ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 11s 406ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 10s 378ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 10s 382ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 10s 373ms/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 10s 383ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 10s 362ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 10s 365ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 10s 373ms/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 10s 372ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 10s 373ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 11s 420ms/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 10s 371ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 10s 391ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 10s 381ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 10s 370ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 9s 364ms/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 10s 373ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 10s 375ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0033Restoring model weights from the end of the best epoch: 17.\n",
      "26/26 [==============================] - 10s 370ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 37: early stopping\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "history = angle_model.fit(\n",
    "    angle_train_generator,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=angle_val_generator,\n",
    "    callbacks=[es],\n",
    "    epochs=100\n",
    ")\n",
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 9s 83ms/step - loss: 0.0059\n",
      "93/93 [==============================] - 8s 76ms/step - loss: 0.0059\n"
     ]
    }
   ],
   "source": [
    "angle_model1 = load_model(\"angle-model.h5\")\n",
    "angle_model = load_model(\"best-angle-model.h5\")\n",
    "\n",
    "test_loss = angle_model.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")\n",
    "test_loss = angle_model1.evaluate(\n",
    "    angle_eval_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:43:14.787757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 11:43:14.789762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 11:43:14.789808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 11:43:14.789829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 11:43:15.727490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 11:43:15.727855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 11:43:15.727865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-31 11:43:15.727893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-31 11:43:15.727941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 10, 1280)      2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 4, 128)         1474688   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 3, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               196736    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,930,561\n",
      "Trainable params: 3,033,985\n",
      "Non-trainable params: 896,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "angle_model = load_model(\"angle-model-fine-tuning.h5\")\n",
    "angle_model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis_cw_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a484844ebfe5c5f2d592fb88147ab4deecd2e175b71cbb396b7b8e5c1ee0b4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
