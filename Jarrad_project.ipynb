{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnIbwiK7Ohv2",
    "outputId": "323b604b-5c49-4b2c-cf17-b06f09ffc176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from 'c:\\\\Users\\\\elec_\\\\anacon\\\\anaconda3\\\\envs\\\\MLIS2car\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "print(tf.version)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "#import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "49wbEaM1PCCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id   angle  speed   filename\n",
      "0             1  0.4375    0.0      1.png\n",
      "1             2  0.8125    1.0      2.png\n",
      "2             3  0.4375    1.0      3.png\n",
      "3             4  0.6250    1.0      4.png\n",
      "4             5  0.5000    0.0      5.png\n",
      "...         ...     ...    ...        ...\n",
      "13788     13794  0.6250    1.0  13794.png\n",
      "13789     13795  0.4375    1.0  13795.png\n",
      "13790     13796  0.5625    0.0  13796.png\n",
      "13791     13797  0.6250    0.0  13797.png\n",
      "13792     13798  0.6875    1.0  13798.png\n",
      "\n",
      "[13793 rows x 4 columns]\n",
      "Found 13798 files belonging to 1 classes.\n",
      "Using 11039 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_size = [240, 320]\n",
    "\n",
    "df = pd.read_csv(r'machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "df['filename'] = df[\"image_id\"].astype(str) + \".png\"\n",
    "#df['label'] = [df[\"angle\"], df[\"speed\"]]\n",
    "print(df)\n",
    "\n",
    "\n",
    "#x_train = df[0:int(len(df) * 0.7)]\n",
    "x_validate = df[int(len(df) * 0.8):int(len(df) * 0.9)]\n",
    "x_evaluate = df[int(len(df) * 0.9):]\n",
    "\n",
    "x_train = df[0:int(len(df) * 0.8)]\n",
    "#x_validate = df[int(len(df) * 0.8):]\n",
    "\n",
    "training_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"machine-learning-in-science-ii-2023/training_data\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11034 validated image filenames.\n",
      "Found 1379 validated image filenames.\n",
      "Found 1380 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "    dataframe=x_train,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    batch_size=16,\n",
    "    class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=x_validate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    class_mode='other')\n",
    "\n",
    "evaluate_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "eval_generator = evaluate_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"angle\",\"speed\"],\n",
    "    target_size=img_size,\n",
    "    class_mode='other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [],
   "source": [
    "shape = (*img_size, 3) # inherited image size with 3 color filters\n",
    "\n",
    "# CNN base\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3),strides=(2, 2), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten()),\n",
    "\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2,  activation='relu', kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEzHX-7ESeCl",
    "outputId": "b1ad1ed9-87ef-4a37-b392-59e9ebb807d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_57 (Conv2D)          (None, 119, 159, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 119, 159, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 59, 79, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 57, 77, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 28, 38, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 28, 38, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 14, 19, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 6, 9, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  (None, 6, 9, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 4, 7, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (None, 4, 7, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 4, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 1792)              0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                114752    \n",
      "                                                                 \n",
      " batch_normalization_83 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191,882\n",
      "Trainable params: 191,322\n",
      "Non-trainable params: 560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5loIug93TW1E",
    "outputId": "f470435d-196d-435b-cb96-39fc27d0552f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "690/690 [==============================] - 101s 144ms/step - loss: 0.0405 - val_loss: 0.0254\n",
      "Epoch 2/5\n",
      "690/690 [==============================] - 100s 144ms/step - loss: 0.0304 - val_loss: 0.0233\n",
      "Epoch 3/5\n",
      "690/690 [==============================] - 102s 147ms/step - loss: 0.0279 - val_loss: 0.0351\n",
      "Epoch 4/5\n",
      "690/690 [==============================] - 99s 143ms/step - loss: 0.0271 - val_loss: 0.0453\n",
      "Epoch 5/5\n",
      "690/690 [==============================] - 104s 151ms/step - loss: 0.0239 - val_loss: 0.0227\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6I2vJFiiTkQE",
    "outputId": "83815ac0-1917-4508-b093-bbf2ce91ea08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1020 files belonging to 1 classes.\n",
      "32/32 [==============================] - 2s 66ms/step\n",
      "(1020, 2)\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('model.h6')\n",
    "\n",
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"machine-learning-in-science-ii-2023/test_data\",\n",
    "    image_size=img_size,\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "test_images = test_images.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "prediction = model.predict(test_images)\n",
    "print(prediction.shape)\n",
    "import math\n",
    "\n",
    "a= prediction[:,0]\n",
    "b= prediction[:,1]\n",
    "b+=0.5\n",
    "b= np.floor(b)\n",
    "\n",
    "submissiondata={\"angle\":a , \"speed\":b} \n",
    "df = pd.DataFrame(submissiondata)\n",
    "df.index += 1 \n",
    "df.to_csv('Submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 9s 197ms/step - loss: 0.0229\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'filename'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m test_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(\n\u001b[0;32m      6\u001b[0m     eval_generator,\n\u001b[0;32m      7\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m test_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m test_generator \u001b[39m=\u001b[39m test_datagen\u001b[39m.\u001b[39;49mflow_from_dataframe(\n\u001b[0;32m     13\u001b[0m     dataframe\u001b[39m=\u001b[39;49mx_evaluate,\n\u001b[0;32m     14\u001b[0m     directory\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmachine-learning-in-science-ii-2023/training_data/training_data\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m     x_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfilename\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     16\u001b[0m     target_size\u001b[39m=\u001b[39;49mimg_size,\n\u001b[0;32m     17\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     21\u001b[0m \u001b[39m#test_loss\u001b[39;00m\n\u001b[0;32m     23\u001b[0m predict_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_generator, verbose \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\keras\\preprocessing\\image.py:1808\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1801\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdrop_duplicates\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m   1802\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1803\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1804\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1805\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1806\u001b[0m     )\n\u001b[1;32m-> 1808\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameIterator(\n\u001b[0;32m   1809\u001b[0m     dataframe,\n\u001b[0;32m   1810\u001b[0m     directory,\n\u001b[0;32m   1811\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1812\u001b[0m     x_col\u001b[39m=\u001b[39;49mx_col,\n\u001b[0;32m   1813\u001b[0m     y_col\u001b[39m=\u001b[39;49my_col,\n\u001b[0;32m   1814\u001b[0m     weight_col\u001b[39m=\u001b[39;49mweight_col,\n\u001b[0;32m   1815\u001b[0m     target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1816\u001b[0m     color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1817\u001b[0m     classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1818\u001b[0m     class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1819\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1820\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1821\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1822\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1823\u001b[0m     save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1824\u001b[0m     save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1825\u001b[0m     save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1826\u001b[0m     subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1827\u001b[0m     interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1828\u001b[0m     validate_filenames\u001b[39m=\u001b[39;49mvalidate_filenames,\n\u001b[0;32m   1829\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1830\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\keras\\preprocessing\\image.py:968\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m dtype\n\u001b[0;32m    967\u001b[0m \u001b[39m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[1;32m--> 968\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params(df, x_col, y_col, weight_col, classes)\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    970\u001b[0m     validate_filenames\n\u001b[0;32m    971\u001b[0m ):  \u001b[39m# check which image files are valid and keep them\u001b[39;00m\n\u001b[0;32m    972\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\keras\\preprocessing\\image.py:1029\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[1;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1024\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIf class_mode=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, y_col must be a list. Received \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1025\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_mode, \u001b[39mtype\u001b[39m(y_col)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m   1026\u001b[0m         )\n\u001b[0;32m   1027\u001b[0m     )\n\u001b[0;32m   1028\u001b[0m \u001b[39m# check that filenames/filepaths column values are all strings\u001b[39;00m\n\u001b[1;32m-> 1029\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(df[x_col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m))):\n\u001b[0;32m   1030\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1031\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll values in column x_col=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m must be strings.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(x_col)\n\u001b[0;32m   1032\u001b[0m     )\n\u001b[0;32m   1033\u001b[0m \u001b[39m# check labels are string if class_mode is binary or sparse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\elec_\\anacon\\anaconda3\\envs\\MLIS2car\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'filename'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_evaluate = df[int(len(df) * 0.8):]\n",
    "\n",
    "test_loss = model.evaluate(\n",
    "    eval_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=x_evaluate,\n",
    "    directory=\"machine-learning-in-science-ii-2023/training_data/training_data\",\n",
    "    x_col=\"filename\",\n",
    "    target_size=img_size,\n",
    "    class_mode=None)\n",
    "\n",
    "\n",
    "\n",
    "#test_loss\n",
    "\n",
    "predict_model = model.predict(test_generator, verbose =1)\n",
    "\n",
    "# y = np.concatenate([y for x, y in x_evaluate], axis=0)\n",
    "# true = np.argmax(y, axis = 1)\n",
    "\n",
    "# print(true)\n",
    "# predict_model = np.argmax(predict_model, axis = 1)\n",
    "# print(predict_model)\n",
    "\n",
    "# print(classification_report(true, predict_model, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlis2_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83badb9abfa833c8f944a253dee1819f5989bd8424f7fb8e0e95b6cecc08b674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
