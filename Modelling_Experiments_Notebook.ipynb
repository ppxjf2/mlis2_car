{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1778398d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "import json\n",
    "from IPython.core.display import SVG\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "\n",
    "import sakthi_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "becfd59d-7760-4ec1-8bb4-a7ef5a1076df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ccfb75c-f0a9-4297-bb53-03c5d34f7ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset_path = \"data/dataset_1\"\n",
    "test_dataset_path = \"machine-learning-in-science-ii-2023/test_data/test_data\"\n",
    "\n",
    "training_labels_path = \"data/combined_training_norm_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb761141-5592-4312-9111-bbf151097d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(14825, 3)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(training_labels_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "   image_id   angle  speed\n0         1  0.4375    0.0\n1         2  0.8125    1.0\n2         3  0.4375    1.0\n3         4  0.6250    1.0\n4         5  0.5000    0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>angle</th>\n      <th>speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.4375</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.8125</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.4375</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.6250</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.5000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "584685af-ba7c-41ff-a5d7-e9403c378b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   image_id   angle  speed                     file_name\n0         1  0.4375    0.0  1_speed-0.0_angle-0.4375.png\n1         2  0.8125    1.0  2_speed-1.0_angle-0.8125.png\n2         3  0.4375    1.0  3_speed-1.0_angle-0.4375.png\n3         4  0.6250    1.0   4_speed-1.0_angle-0.625.png\n4         5  0.5000    0.0     5_speed-0.0_angle-0.5.png",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>angle</th>\n      <th>speed</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.4375</td>\n      <td>0.0</td>\n      <td>1_speed-0.0_angle-0.4375.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.8125</td>\n      <td>1.0</td>\n      <td>2_speed-1.0_angle-0.8125.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.4375</td>\n      <td>1.0</td>\n      <td>3_speed-1.0_angle-0.4375.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.6250</td>\n      <td>1.0</td>\n      <td>4_speed-1.0_angle-0.625.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.5000</td>\n      <td>0.0</td>\n      <td>5_speed-0.0_angle-0.5.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"file_name\"] = df[\"image_id\"].astype(str) + \"_speed-\"+ df[\"speed\"].astype(str) + \"_angle-\" + df[\"angle\"].astype(str) + \".png\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "'1_speed-0.0_angle-0.4375.png'"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"file_name\"][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4375]\n",
      " [0.8125]\n",
      " [0.4375]\n",
      " ...\n",
      " [0.8125]\n",
      " [0.75  ]\n",
      " [0.5   ]]\n",
      "[array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,\n",
      "       0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,\n",
      "       1.    ])]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       angle_0  angle_1  angle_2  angle_3  angle_4  angle_5  angle_6  angle_7  \\\n0          0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n1          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n2          0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n3          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n4          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n...        ...      ...      ...      ...      ...      ...      ...      ...   \n14820      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n14821      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n14822      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n14823      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n14824      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n\n       angle_8  angle_9  angle_10  angle_11  angle_12  angle_13  angle_14  \\\n0          0.0      0.0       0.0       0.0       0.0       0.0       0.0   \n1          0.0      0.0       0.0       0.0       0.0       1.0       0.0   \n2          0.0      0.0       0.0       0.0       0.0       0.0       0.0   \n3          0.0      0.0       1.0       0.0       0.0       0.0       0.0   \n4          1.0      0.0       0.0       0.0       0.0       0.0       0.0   \n...        ...      ...       ...       ...       ...       ...       ...   \n14820      0.0      0.0       0.0       0.0       0.0       1.0       0.0   \n14821      0.0      0.0       0.0       0.0       0.0       0.0       1.0   \n14822      0.0      0.0       0.0       0.0       0.0       1.0       0.0   \n14823      0.0      0.0       0.0       0.0       1.0       0.0       0.0   \n14824      1.0      0.0       0.0       0.0       0.0       0.0       0.0   \n\n       angle_15  angle_16  \n0           0.0       0.0  \n1           0.0       0.0  \n2           0.0       0.0  \n3           0.0       0.0  \n4           0.0       0.0  \n...         ...       ...  \n14820       0.0       0.0  \n14821       0.0       0.0  \n14822       0.0       0.0  \n14823       0.0       0.0  \n14824       0.0       0.0  \n\n[14825 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>angle_0</th>\n      <th>angle_1</th>\n      <th>angle_2</th>\n      <th>angle_3</th>\n      <th>angle_4</th>\n      <th>angle_5</th>\n      <th>angle_6</th>\n      <th>angle_7</th>\n      <th>angle_8</th>\n      <th>angle_9</th>\n      <th>angle_10</th>\n      <th>angle_11</th>\n      <th>angle_12</th>\n      <th>angle_13</th>\n      <th>angle_14</th>\n      <th>angle_15</th>\n      <th>angle_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14820</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14821</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14822</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14823</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14824</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14825 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = df\n",
    "enc = OneHotEncoder()\n",
    "angles = df_preprocessed[\"angle\"].values.reshape(-1, 1)\n",
    "print(angles)\n",
    "enc.fit(angles)\n",
    "print(enc.categories_)\n",
    "ohe_angles = pd.DataFrame(enc.transform(angles).toarray())\n",
    "ohe_angles.columns = [\"angle_{}\".format(col) for col in ohe_angles.columns]\n",
    "ohe_angles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "       image_id   angle  speed                         file_name  angle_0  \\\n0             1  0.4375    0.0      1_speed-0.0_angle-0.4375.png      0.0   \n1             2  0.8125    1.0      2_speed-1.0_angle-0.8125.png      0.0   \n2             3  0.4375    1.0      3_speed-1.0_angle-0.4375.png      0.0   \n3             4  0.6250    1.0       4_speed-1.0_angle-0.625.png      0.0   \n4             5  0.5000    0.0         5_speed-0.0_angle-0.5.png      0.0   \n...         ...     ...    ...                               ...      ...   \n14820     17623  0.8125    1.0  17623_speed-1.0_angle-0.8125.png      0.0   \n14821     17624  0.8750    1.0   17624_speed-1.0_angle-0.875.png      0.0   \n14822     17625  0.8125    1.0  17625_speed-1.0_angle-0.8125.png      0.0   \n14823     17626  0.7500    1.0    17626_speed-1.0_angle-0.75.png      0.0   \n14824     17627  0.5000    0.0     17627_speed-0.0_angle-0.5.png      0.0   \n\n       angle_1  angle_2  angle_3  angle_4  angle_5  ...  angle_7  angle_8  \\\n0          0.0      0.0      0.0      0.0      0.0  ...      1.0      0.0   \n1          0.0      0.0      0.0      0.0      0.0  ...      0.0      0.0   \n2          0.0      0.0      0.0      0.0      0.0  ...      1.0      0.0   \n3          0.0      0.0      0.0      0.0      0.0  ...      0.0      0.0   \n4          0.0      0.0      0.0      0.0      0.0  ...      0.0      1.0   \n...        ...      ...      ...      ...      ...  ...      ...      ...   \n14820      0.0      0.0      0.0      0.0      0.0  ...      0.0      0.0   \n14821      0.0      0.0      0.0      0.0      0.0  ...      0.0      0.0   \n14822      0.0      0.0      0.0      0.0      0.0  ...      0.0      0.0   \n14823      0.0      0.0      0.0      0.0      0.0  ...      0.0      0.0   \n14824      0.0      0.0      0.0      0.0      0.0  ...      0.0      1.0   \n\n       angle_9  angle_10  angle_11  angle_12  angle_13  angle_14  angle_15  \\\n0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n1          0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n2          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n3          0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n4          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n...        ...       ...       ...       ...       ...       ...       ...   \n14820      0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n14821      0.0       0.0       0.0       0.0       0.0       1.0       0.0   \n14822      0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n14823      0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n14824      0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n\n       angle_16  \n0           0.0  \n1           0.0  \n2           0.0  \n3           0.0  \n4           0.0  \n...         ...  \n14820       0.0  \n14821       0.0  \n14822       0.0  \n14823       0.0  \n14824       0.0  \n\n[14825 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>angle</th>\n      <th>speed</th>\n      <th>file_name</th>\n      <th>angle_0</th>\n      <th>angle_1</th>\n      <th>angle_2</th>\n      <th>angle_3</th>\n      <th>angle_4</th>\n      <th>angle_5</th>\n      <th>...</th>\n      <th>angle_7</th>\n      <th>angle_8</th>\n      <th>angle_9</th>\n      <th>angle_10</th>\n      <th>angle_11</th>\n      <th>angle_12</th>\n      <th>angle_13</th>\n      <th>angle_14</th>\n      <th>angle_15</th>\n      <th>angle_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.4375</td>\n      <td>0.0</td>\n      <td>1_speed-0.0_angle-0.4375.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.8125</td>\n      <td>1.0</td>\n      <td>2_speed-1.0_angle-0.8125.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.4375</td>\n      <td>1.0</td>\n      <td>3_speed-1.0_angle-0.4375.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.6250</td>\n      <td>1.0</td>\n      <td>4_speed-1.0_angle-0.625.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.5000</td>\n      <td>0.0</td>\n      <td>5_speed-0.0_angle-0.5.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14820</th>\n      <td>17623</td>\n      <td>0.8125</td>\n      <td>1.0</td>\n      <td>17623_speed-1.0_angle-0.8125.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14821</th>\n      <td>17624</td>\n      <td>0.8750</td>\n      <td>1.0</td>\n      <td>17624_speed-1.0_angle-0.875.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14822</th>\n      <td>17625</td>\n      <td>0.8125</td>\n      <td>1.0</td>\n      <td>17625_speed-1.0_angle-0.8125.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14823</th>\n      <td>17626</td>\n      <td>0.7500</td>\n      <td>1.0</td>\n      <td>17626_speed-1.0_angle-0.75.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14824</th>\n      <td>17627</td>\n      <td>0.5000</td>\n      <td>0.0</td>\n      <td>17627_speed-0.0_angle-0.5.png</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14825 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = pd.concat([df_preprocessed, ohe_angles], axis=1)\n",
    "df_preprocessed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "251ae887-2183-466c-8b39-314cadd466ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11860, 21) 11860\n",
      "(2965, 21) 2965\n"
     ]
    }
   ],
   "source": [
    "train_df, validation_df = train_test_split(df_preprocessed, test_size=0.2, random_state=39, stratify=df[[\"speed\", \"angle\"]])\n",
    "print(train_df.shape, len(train_df[\"image_id\"].unique()))\n",
    "print(validation_df.shape, len(validation_df[\"image_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47fe86aa-fbd4-49ea-9e78-4cc35f4a5dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = os.listdir(test_dataset_path)\n",
    "test_image_id_list = []\n",
    "for file in files:\n",
    "    image_id = file.split(\".\")[0]\n",
    "    test_image_id_list.append(image_id)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"image_id\"]=sorted(test_image_id_list, key=sakthi_helper.natural_keys)\n",
    "test_df[\"file_name\"] = df[\"image_id\"].astype(str) + \".png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "  image_id file_name\n0        1     1.png\n1        2     2.png\n2        3     3.png\n3        4     4.png\n4        5     5.png",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.to_csv(\"submissions/test_submission_template.csv\", index=False)\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "335d119a-f9a8-40e7-a26e-e454d6c6f017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_CLASSES = [2, 17]  # CHANGE HERE, total number of classes               \n",
    "IMG_HEIGHT = 240  # CHANGE HERE, the image height to be resized to  \n",
    "IMG_WIDTH = 320  # CHANGE HERE, the image width to be resized to     \n",
    "CHANNELS = 3  # The 3 color channels, change to 1 if grayscale\n",
    "COLOR_MODE = \"rgb\"\n",
    "BATCH_SIZE = 16\n",
    "SEED = 39\n",
    "AUGMENTATION = \"b-0.5-1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Generators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "407a04b5-2cef-4fd4-b6ce-d1d6d547e982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'data/dataset_1'"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = training_dataset_path\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9ca7dd6-8983-4903-8c98-a240aaa4ce48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1 / 255, horizontal_flip=False , brightness_range=(0.5, 1.5), zca_whitening=False)\n",
    "                                            # contrast_stretching=True, contrast_stretching_range=(2, 98),\n",
    "                                            # histogram_equalization=True ,\n",
    "                                            # adaptive_equalization=True, adaptive_hist_clip_limit=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "train_generator_images_path = dataset_path + \"/train_generator_images_{}\".format(AUGMENTATION) # hf_b_cs_he_ahe_zca\n",
    "pathlib.Path(train_generator_images_path).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e393d3f3-5b38-4c06-ad92-9b8296379056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11860 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_dataframe(train_df, directory=dataset_path, x_col='file_name',\n",
    "                                                     y_col=[\"speed\"]+[\"angle_{}\".format(i) for i in range(17)], weight_col=None,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=COLOR_MODE, classes=None, class_mode='multi_output', \n",
    "                                                     batch_size=BATCH_SIZE, shuffle=True, seed=SEED,\n",
    "                                                     save_to_dir=train_generator_images_path, save_prefix='Aug-', save_format='png',\n",
    "                                                     subset=None, interpolation='nearest', validate_filenames=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b5cb05fe-ab75-49cd-92d8-21a518acd81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2965 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = test_datagen.flow_from_dataframe(validation_df, directory=dataset_path, x_col='file_name',\n",
    "                                                     y_col=[\"speed\"]+[\"angle_{}\".format(i) for i in range(17)], weight_col=None,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=COLOR_MODE, classes=None, class_mode='multi_output', \n",
    "                                                     batch_size=BATCH_SIZE, shuffle=True, seed=SEED,\n",
    "                                                     save_to_dir=None, save_prefix='', save_format='png',\n",
    "                                                     subset=None, interpolation='nearest', validate_filenames=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "449788b0-0bee-44b1-aa0e-1162e1d3ad20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1020 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(test_df, directory=test_dataset_path, x_col='file_name', y_col=None, weight_col=None, \n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=COLOR_MODE, classes=None, class_mode=None, \n",
    "                                                     batch_size=BATCH_SIZE, shuffle=False, seed=SEED,\n",
    "                                                     save_to_dir=None, save_prefix='', save_format='png',\n",
    "                                                     subset=None, interpolation='nearest', validate_filenames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_generator:\n",
    "    print(len(X_batch))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9301e2b6-81be-489e-a4fc-6a6b4f310da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = {}\n",
    "\n",
    "model_ID = model_config['model_id'] = \"1\"\n",
    "model_type = model_config['model_type'] = 'CNN_BC_MC'\n",
    "class_names = model_config['class_names'] = [['Speed_0', 'Speed_1'], ['Angle_0', 'Angle_1', 'Angle_2', 'Angle_3', 'Angle_4', 'Angle_5', 'Angle_6', 'Angle_7', 'Angle_8', 'Angle_9', 'Angle_10', 'Angle_11', 'Angle_12', 'Angle_13', 'Angle_14', 'Angle_15', 'Angle 17']]\n",
    "class_names_short = model_config['class_names_short'] = [['S0', 'S1'], ['A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16']]\n",
    "class_names_dict = model_config['class_names_dict'] = '' ##{0: 'OA', 1: 'G', 2: 'AG', 3: 'HA', 4: 'PG', 5: 'CBG', 6: 'SEG', 7: 'MBG', 8: 'MBAG', 9: 'WOOS'}\n",
    "dataset_ID = model_config['dataset_ID'] = \"dataset_1\"\n",
    "seed = model_config['seed'] = SEED\n",
    "n_classes = model_config['n_classes'] = len(model_config['class_names'])\n",
    "class_weights = model_config['class_weights'] = '' ##{0:1, 1:1 , 2:3, 3:5, 4:5, 5:1}\n",
    "batch_size = model_config['batch_size'] = BATCH_SIZE\n",
    "n_epochs = model_config['n_epochs'] = 10\n",
    "hidden_layers = model_config['hidden_layers'] = ['C16_K3', 'BN', 'MP_2', 'C32_K3', 'BN', 'MP_2', 'C64_K3', 'BN', 'MP_2', 'C128_K3', 'BN', 'MP_2', 'C256_K3', 'BN', 'MP_2', 'F', '256', 'D_0.2', '128', 'D_0.2', '64', 'D_0.2']\n",
    "activation_fns = model_config['activation_fns'] = ['relu', ['sigmoid', 'softmax']]\n",
    "n_layers = model_config['n_layers'] = 0\n",
    "\n",
    "optimizer = model_config['optimizer'] = \"adam\"\n",
    "initializer = model_config['initializer'] = \"glorot_uniform\"\n",
    "loss = model_config['loss'] = [\"binary_crossentropy\", \"categorical_crossentropy\"]\n",
    "loss_short = model_config['loss_short'] = [\"bce\", \"cce\"]\n",
    "metrics = model_config['metrics'] = \"accuracy\"\n",
    "preprocess = model_config['preprocess'] = \"normalize_rescale-[0,1]\"\n",
    "augmentation = model_config['augmentation'] = AUGMENTATION  #\"hf, br_0.4_1.3, zca_w\" #\"-\" # #\n",
    "regularisation = model_config['regularisation'] = \"-\"  #\"1_BN, 1_Dropout_0.3 D\" #\"4_Dropout_0.3 in MP,D\" #\"-\" # # #\"3_Dropout_0.3 in F,D\"  #    #\"6 Batch Norm layers\"   ##  #\"-\"   #\"5_Dropout_0.3 in MP,D\"\n",
    "additional_params = model_config['additional_params'] = \"-\"\n",
    "\n",
    "# ---------- CNN --------------------\n",
    "input_shape = model_config['input_shape'] = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "total_train_samples = model_config['total_train_samples'] = train_df.shape[0]\n",
    "total_validation_samples = model_config['total_validation_samples'] = validation_df.shape[0]\n",
    "train_samples = model_config['train_samples'] = train_df.shape[0]\n",
    "validation_samples = model_config['validation_samples'] = validation_df.shape[0]\n",
    "train_dataset = model_config['train_dataset'] = \"\"\n",
    "validation_dataset = model_config['validation_dataset'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model save path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9d9cfd8-41bb-4028-8b53-96c394cf2a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_save_path = \"models/CNN_models/model_{}_{}\".format(model_ID, model_type)\n",
    "checkpoints_save_path = \"models/CNN_models/model_{}_{}/model_{}_checkpoints\".format(model_ID, model_type, model_ID)\n",
    "pathlib.Path(model_save_path).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(checkpoints_save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the CNN model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a89bc0c4-839f-42fd-a2c7-c69d2d72be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv2d_10_input (InputLayer)   [(None, 240, 320, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 238, 318, 16  448         ['conv2d_10_input[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 238, 318, 16  64         ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 119, 159, 16  0          ['batch_normalization_10[0][0]'] \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 117, 157, 32  4640        ['max_pooling2d_10[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 117, 157, 32  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 58, 78, 32)  0           ['batch_normalization_11[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 76, 64)   18496       ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 56, 76, 64)  256         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 28, 38, 64)  0           ['batch_normalization_12[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 26, 36, 128)  73856       ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 26, 36, 128)  512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 13, 18, 128)  0          ['batch_normalization_13[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 11, 16, 256)  295168      ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 11, 16, 256)  1024       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 5, 8, 256)   0           ['batch_normalization_14[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 10240)        0           ['max_pooling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          2621696     ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          32896       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           8256        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " binary_output (Dense)          (None, 1)            65          ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " multi_output (Dense)           (None, 17)           1105        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,058,610\n",
      "Trainable params: 3,057,618\n",
      "Non-trainable params: 992\n",
      "__________________________________________________________________________________________________\n",
      "Model Summary :  None\n",
      "Model Parameters :  3058610\n",
      "0 conv2d_10_input\n",
      "1 conv2d_10\n",
      "2 batch_normalization_10\n",
      "3 max_pooling2d_10\n",
      "4 conv2d_11\n",
      "5 batch_normalization_11\n",
      "6 max_pooling2d_11\n",
      "7 conv2d_12\n",
      "8 batch_normalization_12\n",
      "9 max_pooling2d_12\n",
      "10 conv2d_13\n",
      "11 batch_normalization_13\n",
      "12 max_pooling2d_13\n",
      "13 conv2d_14\n",
      "14 batch_normalization_14\n",
      "15 max_pooling2d_14\n",
      "16 flatten_2\n",
      "17 dense_6\n",
      "18 dropout_6\n",
      "19 dense_7\n",
      "20 dropout_7\n",
      "21 dense_8\n",
      "22 dropout_8\n",
      "23 binary_output\n",
      "24 multi_output\n",
      "num layers:  25\n",
      "Model_name   :  1_CNN_BC_MC_D-dataset_1_A-b-0.5-1.5_E-10_B-16_PP-normalize_rescale-[0,1]_R--_EXTRA--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "print(input_shape)\n",
    "model = sakthi_helper.create_CNN_model(input_shape, hidden_layers, pretrained_model=None, num_non_trainable_layers=1,\n",
    "                     output_layer={'binary_output': [1, 'sigmoid', 'binary_crossentropy', 'accuracy'], 'multi_output': [17, 'softmax', 'categorical_crossentropy', 'accuracy']},\n",
    "                     init='normal', optimize='adam')\n",
    "\n",
    "print(\"Model Summary : \", model.summary())\n",
    "\n",
    "model_parameters = model.count_params()\n",
    "print(\"Model Parameters : \", model_parameters)\n",
    "\n",
    "n_layers = 0\n",
    "for i, layer in enumerate(model.layers):  # base_model.layers\n",
    "    n_layers += 1\n",
    "    print(i, layer.name)\n",
    "print(\"num layers: \", n_layers)\n",
    "\n",
    "model_name =  \"{}_{}_D-{}_A-{}_E-{}_B-{}_PP-{}_R-{}_EXTRA-{}\".format(model_ID, model_type, dataset_ID, augmentation, n_epochs, batch_size, preprocess,\n",
    "                                                                      regularisation, additional_params)\n",
    "\n",
    "print(\"Model_name   : \", model_name, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35e41145-914e-4e52-a0ec-a2bfab0dbfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_plotted\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"413pt\" height=\"2299pt\" viewBox=\"0.00 0.00 310.00 1724.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 1720)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1720 306,-1720 306,4 -4,4\"/>\n<!-- 2856236462032 -->\n<g id=\"node1\" class=\"node\">\n<title>2856236462032</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"57,-1679.5 57,-1715.5 249,-1715.5 249,-1679.5 57,-1679.5\"/>\n<text text-anchor=\"middle\" x=\"114.5\" y=\"-1693.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv2d_10_input</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"172,-1679.5 172,-1715.5\"/>\n<text text-anchor=\"middle\" x=\"210.5\" y=\"-1693.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">InputLayer</text>\n</g>\n<!-- 2856236458336 -->\n<g id=\"node2\" class=\"node\">\n<title>2856236458336</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"81,-1606.5 81,-1642.5 225,-1642.5 225,-1606.5 81,-1606.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-1620.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv2d_10</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"161,-1606.5 161,-1642.5\"/>\n<text text-anchor=\"middle\" x=\"193\" y=\"-1620.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv2D</text>\n</g>\n<!-- 2856236462032&#45;&gt;2856236458336 -->\n<g id=\"edge1\" class=\"edge\">\n<title>2856236462032-&gt;2856236458336</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1679.67C153,-1671.89 153,-1662.44 153,-1653.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1653.72 153,-1643.72 149.5,-1653.72 156.5,-1653.72\"/>\n</g>\n<!-- 2856239502528 -->\n<g id=\"node3\" class=\"node\">\n<title>2856239502528</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"15,-1533.5 15,-1569.5 291,-1569.5 291,-1533.5 15,-1533.5\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-1547.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_10</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-1533.5 165,-1569.5\"/>\n<text text-anchor=\"middle\" x=\"228\" y=\"-1547.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n</g>\n<!-- 2856236458336&#45;&gt;2856239502528 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2856236458336-&gt;2856239502528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1606.67C153,-1598.89 153,-1589.44 153,-1580.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1580.72 153,-1570.72 149.5,-1580.72 156.5,-1580.72\"/>\n</g>\n<!-- 2856231555472 -->\n<g id=\"node4\" class=\"node\">\n<title>2856231555472</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"40,-1460.5 40,-1496.5 266,-1496.5 266,-1460.5 40,-1460.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-1474.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max_pooling2d_10</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-1460.5 165,-1496.5\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-1474.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MaxPooling2D</text>\n</g>\n<!-- 2856239502528&#45;&gt;2856231555472 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2856239502528-&gt;2856231555472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1533.67C153,-1525.89 153,-1516.44 153,-1507.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1507.72 153,-1497.72 149.5,-1507.72 156.5,-1507.72\"/>\n</g>\n<!-- 2856239504112 -->\n<g id=\"node5\" class=\"node\">\n<title>2856239504112</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"81,-1387.5 81,-1423.5 225,-1423.5 225,-1387.5 81,-1387.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-1401.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv2d_11</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"161,-1387.5 161,-1423.5\"/>\n<text text-anchor=\"middle\" x=\"193\" y=\"-1401.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv2D</text>\n</g>\n<!-- 2856231555472&#45;&gt;2856239504112 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2856231555472-&gt;2856239504112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1460.67C153,-1452.89 153,-1443.44 153,-1434.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1434.72 153,-1424.72 149.5,-1434.72 156.5,-1434.72\"/>\n</g>\n<!-- 2856236479776 -->\n<g id=\"node6\" class=\"node\">\n<title>2856236479776</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"15,-1314.5 15,-1350.5 291,-1350.5 291,-1314.5 15,-1314.5\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-1328.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_11</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-1314.5 165,-1350.5\"/>\n<text text-anchor=\"middle\" x=\"228\" y=\"-1328.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n</g>\n<!-- 2856239504112&#45;&gt;2856236479776 -->\n<g id=\"edge5\" class=\"edge\">\n<title>2856239504112-&gt;2856236479776</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1387.67C153,-1379.89 153,-1370.44 153,-1361.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1361.72 153,-1351.72 149.5,-1361.72 156.5,-1361.72\"/>\n</g>\n<!-- 2856236478768 -->\n<g id=\"node7\" class=\"node\">\n<title>2856236478768</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"40,-1241.5 40,-1277.5 266,-1277.5 266,-1241.5 40,-1241.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-1255.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max_pooling2d_11</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-1241.5 165,-1277.5\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-1255.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MaxPooling2D</text>\n</g>\n<!-- 2856236479776&#45;&gt;2856236478768 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2856236479776-&gt;2856236478768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1314.67C153,-1306.89 153,-1297.44 153,-1288.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1288.72 153,-1278.72 149.5,-1288.72 156.5,-1288.72\"/>\n</g>\n<!-- 2856236511040 -->\n<g id=\"node8\" class=\"node\">\n<title>2856236511040</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"81,-1168.5 81,-1204.5 225,-1204.5 225,-1168.5 81,-1168.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv2d_12</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"161,-1168.5 161,-1204.5\"/>\n<text text-anchor=\"middle\" x=\"193\" y=\"-1182.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv2D</text>\n</g>\n<!-- 2856236478768&#45;&gt;2856236511040 -->\n<g id=\"edge7\" class=\"edge\">\n<title>2856236478768-&gt;2856236511040</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1241.67C153,-1233.89 153,-1224.44 153,-1215.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1215.72 153,-1205.72 149.5,-1215.72 156.5,-1215.72\"/>\n</g>\n<!-- 2856231556432 -->\n<g id=\"node9\" class=\"node\">\n<title>2856231556432</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"15,-1095.5 15,-1131.5 291,-1131.5 291,-1095.5 15,-1095.5\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-1109.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_12</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-1095.5 165,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"228\" y=\"-1109.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n</g>\n<!-- 2856236511040&#45;&gt;2856231556432 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2856236511040-&gt;2856231556432</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1168.67C153,-1160.89 153,-1151.44 153,-1142.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1142.72 153,-1132.72 149.5,-1142.72 156.5,-1142.72\"/>\n</g>\n<!-- 2856236433808 -->\n<g id=\"node10\" class=\"node\">\n<title>2856236433808</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"40,-1022.5 40,-1058.5 266,-1058.5 266,-1022.5 40,-1022.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-1036.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max_pooling2d_12</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-1022.5 165,-1058.5\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-1036.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MaxPooling2D</text>\n</g>\n<!-- 2856231556432&#45;&gt;2856236433808 -->\n<g id=\"edge9\" class=\"edge\">\n<title>2856231556432-&gt;2856236433808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1095.67C153,-1087.89 153,-1078.44 153,-1069.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-1069.72 153,-1059.72 149.5,-1069.72 156.5,-1069.72\"/>\n</g>\n<!-- 2856236529072 -->\n<g id=\"node11\" class=\"node\">\n<title>2856236529072</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"81,-949.5 81,-985.5 225,-985.5 225,-949.5 81,-949.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-963.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv2d_13</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"161,-949.5 161,-985.5\"/>\n<text text-anchor=\"middle\" x=\"193\" y=\"-963.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv2D</text>\n</g>\n<!-- 2856236433808&#45;&gt;2856236529072 -->\n<g id=\"edge10\" class=\"edge\">\n<title>2856236433808-&gt;2856236529072</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-1022.67C153,-1014.89 153,-1005.44 153,-996.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-996.72 153,-986.72 149.5,-996.72 156.5,-996.72\"/>\n</g>\n<!-- 2856236677488 -->\n<g id=\"node12\" class=\"node\">\n<title>2856236677488</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"15,-876.5 15,-912.5 291,-912.5 291,-876.5 15,-876.5\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-890.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_13</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-876.5 165,-912.5\"/>\n<text text-anchor=\"middle\" x=\"228\" y=\"-890.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n</g>\n<!-- 2856236529072&#45;&gt;2856236677488 -->\n<g id=\"edge11\" class=\"edge\">\n<title>2856236529072-&gt;2856236677488</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-949.67C153,-941.89 153,-932.44 153,-923.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-923.72 153,-913.72 149.5,-923.72 156.5,-923.72\"/>\n</g>\n<!-- 2856236677872 -->\n<g id=\"node13\" class=\"node\">\n<title>2856236677872</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"40,-803.5 40,-839.5 266,-839.5 266,-803.5 40,-803.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-817.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max_pooling2d_13</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-803.5 165,-839.5\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-817.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MaxPooling2D</text>\n</g>\n<!-- 2856236677488&#45;&gt;2856236677872 -->\n<g id=\"edge12\" class=\"edge\">\n<title>2856236677488-&gt;2856236677872</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-876.67C153,-868.89 153,-859.44 153,-850.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-850.72 153,-840.72 149.5,-850.72 156.5,-850.72\"/>\n</g>\n<!-- 2856236613984 -->\n<g id=\"node14\" class=\"node\">\n<title>2856236613984</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"81,-730.5 81,-766.5 225,-766.5 225,-730.5 81,-730.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-744.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">conv2d_14</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"161,-730.5 161,-766.5\"/>\n<text text-anchor=\"middle\" x=\"193\" y=\"-744.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Conv2D</text>\n</g>\n<!-- 2856236677872&#45;&gt;2856236613984 -->\n<g id=\"edge13\" class=\"edge\">\n<title>2856236677872-&gt;2856236613984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-803.67C153,-795.89 153,-786.44 153,-777.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-777.72 153,-767.72 149.5,-777.72 156.5,-777.72\"/>\n</g>\n<!-- 2856236605392 -->\n<g id=\"node15\" class=\"node\">\n<title>2856236605392</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"15,-657.5 15,-693.5 291,-693.5 291,-657.5 15,-657.5\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-671.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_14</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-657.5 165,-693.5\"/>\n<text text-anchor=\"middle\" x=\"228\" y=\"-671.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n</g>\n<!-- 2856236613984&#45;&gt;2856236605392 -->\n<g id=\"edge14\" class=\"edge\">\n<title>2856236613984-&gt;2856236605392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-730.67C153,-722.89 153,-713.44 153,-704.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-704.72 153,-694.72 149.5,-704.72 156.5,-704.72\"/>\n</g>\n<!-- 2856236531664 -->\n<g id=\"node16\" class=\"node\">\n<title>2856236531664</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"40,-584.5 40,-620.5 266,-620.5 266,-584.5 40,-584.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-598.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">max_pooling2d_14</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"165,-584.5 165,-620.5\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-598.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MaxPooling2D</text>\n</g>\n<!-- 2856236605392&#45;&gt;2856236531664 -->\n<g id=\"edge15\" class=\"edge\">\n<title>2856236605392-&gt;2856236531664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-657.67C153,-649.89 153,-640.44 153,-631.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-631.72 153,-621.72 149.5,-631.72 156.5,-631.72\"/>\n</g>\n<!-- 2856236434864 -->\n<g id=\"node17\" class=\"node\">\n<title>2856236434864</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"93.5,-511.5 93.5,-547.5 212.5,-547.5 212.5,-511.5 93.5,-511.5\"/>\n<text text-anchor=\"middle\" x=\"126\" y=\"-525.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">flatten_2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"158.5,-511.5 158.5,-547.5\"/>\n<text text-anchor=\"middle\" x=\"185.5\" y=\"-525.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Flatten</text>\n</g>\n<!-- 2856236531664&#45;&gt;2856236434864 -->\n<g id=\"edge16\" class=\"edge\">\n<title>2856236531664-&gt;2856236434864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-584.67C153,-576.89 153,-567.44 153,-558.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-558.72 153,-548.72 149.5,-558.72 156.5,-558.72\"/>\n</g>\n<!-- 2856240040496 -->\n<g id=\"node18\" class=\"node\">\n<title>2856240040496</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"96,-438.5 96,-474.5 210,-474.5 210,-438.5 96,-438.5\"/>\n<text text-anchor=\"middle\" x=\"127.5\" y=\"-452.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_6</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-438.5 159,-474.5\"/>\n<text text-anchor=\"middle\" x=\"184.5\" y=\"-452.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 2856236434864&#45;&gt;2856240040496 -->\n<g id=\"edge17\" class=\"edge\">\n<title>2856236434864-&gt;2856240040496</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-511.67C153,-503.89 153,-494.44 153,-485.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-485.72 153,-475.72 149.5,-485.72 156.5,-485.72\"/>\n</g>\n<!-- 2856236507872 -->\n<g id=\"node19\" class=\"node\">\n<title>2856236507872</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"83,-365.5 83,-401.5 223,-401.5 223,-365.5 83,-365.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_6</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-365.5 159,-401.5\"/>\n<text text-anchor=\"middle\" x=\"191\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n</g>\n<!-- 2856240040496&#45;&gt;2856236507872 -->\n<g id=\"edge18\" class=\"edge\">\n<title>2856240040496-&gt;2856236507872</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-438.67C153,-430.89 153,-421.44 153,-412.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-412.72 153,-402.72 149.5,-412.72 156.5,-412.72\"/>\n</g>\n<!-- 2856236644000 -->\n<g id=\"node20\" class=\"node\">\n<title>2856236644000</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"96,-292.5 96,-328.5 210,-328.5 210,-292.5 96,-292.5\"/>\n<text text-anchor=\"middle\" x=\"127.5\" y=\"-306.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_7</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-292.5 159,-328.5\"/>\n<text text-anchor=\"middle\" x=\"184.5\" y=\"-306.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 2856236507872&#45;&gt;2856236644000 -->\n<g id=\"edge19\" class=\"edge\">\n<title>2856236507872-&gt;2856236644000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-365.67C153,-357.89 153,-348.44 153,-339.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-339.72 153,-329.72 149.5,-339.72 156.5,-339.72\"/>\n</g>\n<!-- 2856236613888 -->\n<g id=\"node21\" class=\"node\">\n<title>2856236613888</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"83,-219.5 83,-255.5 223,-255.5 223,-219.5 83,-219.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-233.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_7</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-219.5 159,-255.5\"/>\n<text text-anchor=\"middle\" x=\"191\" y=\"-233.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n</g>\n<!-- 2856236644000&#45;&gt;2856236613888 -->\n<g id=\"edge20\" class=\"edge\">\n<title>2856236644000-&gt;2856236613888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-292.67C153,-284.89 153,-275.44 153,-266.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-266.72 153,-256.72 149.5,-266.72 156.5,-266.72\"/>\n</g>\n<!-- 2856236585264 -->\n<g id=\"node22\" class=\"node\">\n<title>2856236585264</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"96,-146.5 96,-182.5 210,-182.5 210,-146.5 96,-146.5\"/>\n<text text-anchor=\"middle\" x=\"127.5\" y=\"-160.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_8</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-146.5 159,-182.5\"/>\n<text text-anchor=\"middle\" x=\"184.5\" y=\"-160.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 2856236613888&#45;&gt;2856236585264 -->\n<g id=\"edge21\" class=\"edge\">\n<title>2856236613888-&gt;2856236585264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-219.67C153,-211.89 153,-202.44 153,-193.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-193.72 153,-183.72 149.5,-193.72 156.5,-193.72\"/>\n</g>\n<!-- 2856231555520 -->\n<g id=\"node23\" class=\"node\">\n<title>2856231555520</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"83,-73.5 83,-109.5 223,-109.5 223,-73.5 83,-73.5\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-87.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_8</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-73.5 159,-109.5\"/>\n<text text-anchor=\"middle\" x=\"191\" y=\"-87.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n</g>\n<!-- 2856236585264&#45;&gt;2856231555520 -->\n<g id=\"edge22\" class=\"edge\">\n<title>2856236585264-&gt;2856231555520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153,-146.67C153,-138.89 153,-129.44 153,-120.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.5,-120.72 153,-110.72 149.5,-120.72 156.5,-120.72\"/>\n</g>\n<!-- 2856236547040 -->\n<g id=\"node24\" class=\"node\">\n<title>2856236547040</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-36.5 146,-36.5 146,-0.5 0,-0.5\"/>\n<text text-anchor=\"middle\" x=\"47.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">binary_output</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"95,-0.5 95,-36.5\"/>\n<text text-anchor=\"middle\" x=\"120.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 2856231555520&#45;&gt;2856236547040 -->\n<g id=\"edge23\" class=\"edge\">\n<title>2856231555520-&gt;2856236547040</title>\n<path fill=\"none\" stroke=\"black\" d=\"M134.04,-73.67C124.05,-64.81 111.61,-53.77 100.58,-43.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"103.03,-41.48 93.23,-37.46 98.39,-46.71 103.03,-41.48\"/>\n</g>\n<!-- 2856236651568 -->\n<g id=\"node25\" class=\"node\">\n<title>2856236651568</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"164,-0.5 164,-36.5 302,-36.5 302,-0.5 164,-0.5\"/>\n<text text-anchor=\"middle\" x=\"207.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">multi_output</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"251,-0.5 251,-36.5\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 2856231555520&#45;&gt;2856236651568 -->\n<g id=\"edge24\" class=\"edge\">\n<title>2856231555520-&gt;2856236651568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M171.96,-73.67C181.95,-64.81 194.39,-53.77 205.42,-43.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"207.61,-46.71 212.77,-37.46 202.97,-41.48 207.61,-46.71\"/>\n</g>\n</g>\n</svg>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file=model_save_path + \"\\\\{}_plot.png\".format(model_name))\n",
    "print(\"model_plotted\")\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save model config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "959d1b4f-2f3b-4c6b-9078-eec58de85c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_config_path :  models/CNN_models/model_1_CNN_BC_MC\n",
      "Model_config_saved in \n",
      " models/CNN_models/model_1_CNN_BC_MC\\model_1_config.json\n"
     ]
    }
   ],
   "source": [
    "#--------------------------   SAVE MODEL CONFIGURATION  -------------------------------------------\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "model_config_path = model_save_path\n",
    "pathlib.Path(model_config_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Model_config_path : \", model_config_path)\n",
    "\n",
    "model_config_file = model_config_path + \"\\\\model_{}_config.json\".format(model_ID)\n",
    "\n",
    "with open(model_config_file, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    print(\"Model_config_saved in \\n {}\".format(model_config_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f54c9f1-869b-4b14-88cf-8ff1144fdc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_info_file saved in \n",
      " models/CNN_models/model_1_CNN_BC_MC\\model_1_build_details.json\n"
     ]
    }
   ],
   "source": [
    "#---------------------------  SAVE MODEL DETAILS  -------------------------------------------------\n",
    "\n",
    "model_info_file = model_save_path + \"\\\\model_{}_build_details.json\".format(model_ID)\n",
    "\n",
    "with open(model_info_file, 'w') as outfile:\n",
    "    json.dump(model_config, outfile, indent=4)\n",
    "    print(\"model_info_file saved in \\n {}\".format(model_info_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c00b9ed0-302d-494c-b40f-ca869a1e2eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of header list :  33\n",
      "Length of model details_list :  24\n"
     ]
    }
   ],
   "source": [
    "#--------------------------  CSV DATA  ----------------------------------------------------\n",
    "\n",
    "header_list = []\n",
    "header_list.append('Model ID')\n",
    "header_list.append('Model Type')\n",
    "header_list.append('Dataset ID')\n",
    "header_list.append('Total train Samples')\n",
    "header_list.append('Total Validation samples')\n",
    "header_list.append('Train Samples')\n",
    "header_list.append('Validation Samples')\n",
    "header_list.append('Seed')\n",
    "header_list.append('Input shape')\n",
    "header_list.append('N classes')\n",
    "header_list.append('Class names')\n",
    "header_list.append('Class weights')\n",
    "header_list.append('Preprocessing')\n",
    "header_list.append('Augmentation')\n",
    "header_list.append('N layers')\n",
    "header_list.append('Architecture')\n",
    "header_list.append('Model Parameters')\n",
    "header_list.append('Initializer')\n",
    "header_list.append('Optimizer')\n",
    "header_list.append('Loss function')\n",
    "header_list.append('Regularisation')\n",
    "header_list.append('Metrics')\n",
    "header_list.append('Batch size')\n",
    "header_list.append('N epochs')\n",
    "\n",
    "header_list.append('Train loss')\n",
    "header_list.append('Train accuracy')\n",
    "header_list.append('Test loss')\n",
    "header_list.append('Test accuracy')\n",
    "header_list.append('Sub Model ID')\n",
    "header_list.append('Validation loss')\n",
    "header_list.append('Validation accuracy')\n",
    "header_list.append('Additional params')\n",
    "header_list.append('Remarks')\n",
    "\n",
    "model_details = []\n",
    "model_details.append(model_ID)\n",
    "model_details.append(model_type)\n",
    "model_details.append(dataset_ID)\n",
    "model_details.append(total_train_samples)\n",
    "model_details.append(total_validation_samples)\n",
    "model_details.append(train_samples)\n",
    "model_details.append(validation_samples)\n",
    "model_details.append(seed)\n",
    "model_details.append(input_shape)\n",
    "model_details.append(n_classes)\n",
    "model_details.append(class_names)\n",
    "model_details.append(class_weights)\n",
    "model_details.append(preprocess)\n",
    "model_details.append(augmentation)\n",
    "model_details.append(n_layers)\n",
    "model_details.append(hidden_layers)\n",
    "model_details.append(model_parameters)\n",
    "model_details.append(initializer)\n",
    "model_details.append(optimizer)\n",
    "model_details.append(loss_short)\n",
    "model_details.append(regularisation)\n",
    "model_details.append(metrics)\n",
    "model_details.append(batch_size)\n",
    "model_details.append(n_epochs)\n",
    "\n",
    "print(\"Length of header list : \", len(header_list))\n",
    "print(\"Length of model details_list : \", len(model_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d494152-50ea-4947-bf3c-8e65749947bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------  CALLBACKS  --------------------------------------------------------\n",
    "\n",
    "# metrics_1 = Metrics()\n",
    "\n",
    "#------------  CHECKPOINTS  -----------------------\n",
    "\n",
    "model_metrics = \"_{epoch:02d}-{loss:.4f}-{acc:.4f}-{val_loss:.4f}-{val_acc:.4f}\"\n",
    "\n",
    "filepath = checkpoints_save_path + \"\\\\{}_weights\".format(model_ID) + model_metrics + \".hdf5\"\n",
    "check_point = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False,\n",
    "                              save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "#-------------  CSV LOGGER  ----------------------\n",
    "\n",
    "# CSVLogger(filename, separator=',', append=False)\n",
    "csv_log_path = model_save_path + '\\\\model_{}_training_{}.log'.format(model_ID, int(time.time()))\n",
    "csv_logger = CSVLogger(csv_log_path, append=False)\n",
    "\n",
    "#-------------  EARLY STOPPING  --------------------\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=20)\n",
    "\n",
    "# reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4,\n",
    "                                   # mode='min')\n",
    "\n",
    "#-------------  TENSORBOARD  ------------------------\n",
    "\n",
    "NAME = \"model_{}_logs_{}\".format(model_ID, int(time.time()))\n",
    "tensorboard_path = model_save_path + \"\\\\logs\\\\{}\".format(NAME)\n",
    "pathlib.Path(tensorboard_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd5dcfc0-eda4-4be6-9182-fdc4299e3842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 17) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[97], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_train_samples\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# class_weight=class_weights,\u001B[39;49;00m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mvalidation_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_validation_samples\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcsv_logger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorboard\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\py39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filearod6n20.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\geeks\\py39\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 17) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                                      epochs=n_epochs,\n",
    "                                      steps_per_epoch= total_train_samples/BATCH_SIZE,\n",
    "                                      verbose=1, # class_weight=class_weights,\n",
    "                                      validation_data= validation_generator,\n",
    "                                      validation_steps= total_validation_samples/BATCH_SIZE,\n",
    "                                      callbacks=[csv_logger, check_point, early_stopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662182ab-b028-47d4-be66-d2d7c6b6b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------  MODEL TRAINING HISTORY  ----------------------------------------------------\n",
    "\n",
    "hist = [history.history]\n",
    "print(hist, end=\"\\n\\n\")\n",
    "# print(hist[0]['acc'][-1])\n",
    "train_loss = hist[0]['loss'][-1]\n",
    "train_accuracy = hist[0]['acc'][-1]\n",
    "val_loss = hist[0]['val_loss'][-1]\n",
    "val_accuracy = hist[0]['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d3f3c-218c-44c9-88a9-9bb17f53e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------  SAVING MODEL  ------------------------------------------------------\n",
    "\n",
    "end_epoch = len(hist[0]['loss'])\n",
    "\n",
    "model_stats = \"{:.4f}_{:.4f}_{:.4f}-{:.4f}\".format(train_loss ,train_accuracy ,val_loss ,val_accuracy)\n",
    "\n",
    "model.save(model_save_path + \"\\\\{}_end_epoch_{}_{}.h5\".format(model_ID, end_epoch, model_stats))\n",
    "print(\"model saved in \\n {}\".format(model_save_path))\n",
    "\n",
    "# serialize weights to HDF5\n",
    "\n",
    "model.save_weights(model_save_path + \"\\\\model_{}_end_epoch_{}_weights_{}.h5\".format(model_ID, end_epoch, model_stats))\n",
    "print(\"model weights saved in \\n {}\".format(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9f6c9-c52f-40e1-b7a4-ccee88f56c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------  SAVE PICKLE FILE  -----------------------------------------------\n",
    "\n",
    "joblib.dump(model, model_save_path + \"\\\\model_{}_end_epoch_{}_weights_{}.pickle\".format(model_ID, end_epoch, model_stats))\n",
    "\n",
    "#-----------------------------------  PLOT TRAINING HISTORY  --------------------------------------------\n",
    "\n",
    "history_plot_save_path = model_save_path + \"\\\\{}_Training_Stats.png\".format(model_name)\n",
    "\n",
    "sakthi_helper.plot_histories(hist, history_plot_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f1dc8-0063-47df-88b1-b3708dbf0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ID = \"51F47\"\n",
    "\n",
    "model_type = \"CNN_BC_MC\"  # CNN_C_R   # CNN_R\n",
    "\n",
    "epoch_ID = 14  #51F47_weights_14-0.0417-0.9856-0.1764-0.9602\n",
    "\n",
    "dataset_ID = \"3CDR_3\" #\"\"CGA_18\"\n",
    "\n",
    "model_save_path = \"models/CNN_models/model_{}_{}\".format(model_ID, model_type)\n",
    "checkpoints_save_path = \"models/CNN_models/model_{}_{}/Model_{}_Checkpoints\".format(model_ID, model_type, model_ID)\n",
    "\n",
    "model_config_file = model_save_path + \"\\\\model_{}_config.yaml\".format(model_ID)\n",
    "\n",
    "weight_files = os.listdir(checkpoints_save_path)\n",
    "print(weight_files)\n",
    "\n",
    "for i, file in enumerate(sorted(weight_files)):\n",
    "\n",
    "    # if i == min_val_loss_index or i == max_val_acc_index:\n",
    "    # print(file)\n",
    "    epoch_num = file.split(\"_\")[-1].split(\"-\")[0]\n",
    "    # print(\"Epoch num : \", epoch_num)\n",
    "\n",
    "    if int(epoch_num) == epoch_ID:\n",
    "        print(file)\n",
    "\n",
    "        weight_file_name = file\n",
    "\n",
    "\n",
    "## weight_file_name = \"{}_weights_16-0.0379-0.9864-0.1782-0.9571.hdf5\".format(model_ID)\n",
    "\n",
    "weight_stats = weight_file_name.split(\"_\")[-1]\n",
    "epoch_name = (weight_stats).split(\"-\")[0]\n",
    "print(\"Model loaded from Epoch : {}\".format(epoch_name))\n",
    "sub_model_ID = int(epoch_name)\n",
    "\n",
    "#--------  LOADING MODEL WEIGHTS  ----------------\n",
    "selected_model_weights_file = checkpoints_save_path + \"\\\\\" + weight_file_name # .format(model_ID, n_epochs)\n",
    "\n",
    "src_file = selected_model_weights_file\n",
    "\n",
    "sub_model_save_path = model_save_path + \"\\\\{}_SubModel_{}_Val_Dataset_{}\\\\\".format(model_ID, sub_model_ID, dataset_ID)\n",
    "pathlib.Path(sub_model_save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dest_file = sub_model_save_path + weight_file_name\n",
    "\n",
    "if not os.path.isfile(dest_file):\n",
    "    shutil.copy2(src_file, dest_file)\n",
    "else:\n",
    "    print(\"Weight file already exists in Model directory\")\n",
    "\n",
    "sub_model_weights_file = dest_file\n",
    "\n",
    "model_config_file = model_save_path + \"\\\\model_{}_config.yaml\".format(model_ID)\n",
    "\n",
    "loaded_model = sakthi_helper.get_ML_model(model_config_file, sub_model_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7329f91-7780-4509-aa28-453f066b8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------  MODEL EVALUATION  ---------------------------------------------------\n",
    "\n",
    "loss_and_metrics = loaded_model.evaluate_generator(validation_generator,\n",
    "                                                   steps=total_validation_samples / BATCH_SIZE, verbose=1)\n",
    "\n",
    "print(\"Loss and Metrics : \", loss_and_metrics)\n",
    "\n",
    "eval_loss = round(loss_and_metrics[0], ndigits=4)\n",
    "eval_accuracy = round(loss_and_metrics[1] * 100 , ndigits=2)\n",
    "\n",
    "print(\"{}: {:.4f}\".format(loaded_model.metrics_names[0], eval_loss))\n",
    "print(\"{}: {:.2f}\".format(loaded_model.metrics_names[1], eval_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b989929-686b-4dc0-8de2-30cf4db2b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------  ML EXPERIMENT DOCUMENTATION  -----------------------------------------------------\n",
    "\n",
    "train_loss = float(weight_stats.split(\"-\")[1])\n",
    "train_accuracy = float(weight_stats.split(\"-\")[2]) * 100\n",
    "validation_loss = eval_loss\n",
    "validation_accuracy = eval_accuracy\n",
    "test_loss = '-'\n",
    "test_accuracy = '-'\n",
    "\n",
    "model_details.append(train_loss)\n",
    "model_details.append(train_accuracy)\n",
    "model_details.append(test_loss)\n",
    "model_details.append(test_accuracy)\n",
    "model_details.append(sub_model_ID)\n",
    "model_details.append(validation_loss)\n",
    "model_details.append(validation_accuracy)\n",
    "\n",
    "print(train_loss)\n",
    "print(train_accuracy)\n",
    "print(test_loss)\n",
    "print(test_accuracy)\n",
    "print(validation_loss)\n",
    "print(validation_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "model_details.append(model_config['additional_params'])\n",
    "\n",
    "remarks = \"-\"\n",
    "model_details.append(\"-\")\n",
    "\n",
    "print(\"-----------\")\n",
    "# print(len(header_list))\n",
    "print(len(model_details))\n",
    "\n",
    "print(model_details)\n",
    "\n",
    "ML_models_path = \"models/CNN_models/\"\n",
    "CNN_model_results_file = \"\\\\CNN_model_results_New.csv\"\n",
    "\n",
    "CNN_model_results_csv_path = ML_models_path + CNN_model_results_file\n",
    "\n",
    "\n",
    "with open(CNN_model_results_csv_path, 'a', newline='') as file:\n",
    "    file_empty = os.stat(CNN_model_results_csv_path).st_size == 0\n",
    "    csv_writer = csv.writer(file, lineterminator=\"\\n\")\n",
    "\n",
    "    if file_empty:\n",
    "        csv_writer.writerow(header_list)\n",
    "    csv_writer.writerow(model_details)\n",
    "    print(\"Written Experiment stats to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7c21b-768b-4cdc-9b74-14125696e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------- INFERENCE --------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7571b-24b5-4bf1-930b-f6ae7de83dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------  PLOTING CONFUSION MATRIX  ----------------------------------------\n",
    "# print(Y_pred_list)\n",
    "# print(Y_test_list)\n",
    "#\n",
    "# print(\"\\n\", pred_val_list)\n",
    "# print(y_val_list)\n",
    "\n",
    "cnf_matrix = sakthi_helper.confusion_matrix(Y_test_list, Y_pred_list)\n",
    "\n",
    "print(cnf_matrix)\n",
    "\n",
    "cnf_plot_save_path = sub_model_save_path + \"\\\\Model_{}-{}_Val_Dataset_{}_cnf_matrix.png\".format(model_ID, sub_model_ID, dataset_ID)\n",
    "\n",
    "sakthi_helper.plot_confusion_matrix(cnf_matrix, class_names, cnf_plot_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d6196-2c80-4ff2-9334-d11214fd837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------  PLOTTING ROC CURVES  ---------------------------------------------\n",
    "\n",
    "roc_plot_save_path_full = sub_model_save_path + \"\\\\Model_{}-{}_Val_Dataset_{}_full_ROC_plot.png\".format(model_ID, sub_model_ID, dataset_ID)\n",
    "roc_plot_save_path_zoom = sub_model_save_path + \"\\\\Model_{}-{}_Val_Dataset_{}_zoomed_ROC_plot.png\".format(model_ID, sub_model_ID, dataset_ID)\n",
    "\n",
    "# print(Y_one_hot_array.shape)\n",
    "# print(Y_pred_one_hot_array.shape)\n",
    "\n",
    "\n",
    "# sakthi_helper.plot_ROC_curves(Y_one_hot_array, Y_pred_one_hot_array, n_classes, roc_plot_save_path_full, roc_plot_save_path_zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d18457-54f7-422f-9109-4eadecea483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------  PLOT CLASSIFICATION REPORT  ----------------------------------\n",
    "\n",
    "report = sakthi_helper.classification_report(Y_test_array, Y_pred_array, target_names=class_names)\n",
    "print(\"Classification Report : \", report)\n",
    "\n",
    "report_plot_save_path = sub_model_save_path + \"\\\\Model_{}-{}_Val_Dataset_{}_Classification_Report.png\".format(model_ID, sub_model_ID, dataset_ID)\n",
    "\n",
    "sakthi_helper.plot_classification_report(report, report_plot_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d73fa8-3a22-4be5-965e-d17804af9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------  SAVE CLASSIFICATION REPORT AS CSV  ------------------------------------\n",
    "\n",
    "report_save_path = sub_model_save_path + \"\\\\Model_{}-{}_Val_Dataset_{}_Classification_Report.csv\".format(model_ID,\n",
    "                                                                                               sub_model_ID, dataset_ID)\n",
    "\n",
    "report_df = sakthi_helper.pandas_classification_report(Y_test_array, Y_pred_array, class_names)\n",
    "\n",
    "print(report_df)\n",
    "\n",
    "report_df.to_csv(report_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8466233-7532-4da8-bf26-627b15798799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4553a0-710b-47b7-b4b4-737e408dedf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py39",
   "language": "python",
   "display_name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
